{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Vortex–Sentiment Adaptive Volatility (VSAV) Strategy\"\n",
        "author:\n",
        "  - name: Group Data Oracles\n",
        "    affiliations:\n",
        "      - name: Boston University\n",
        "        city: Boston\n",
        "        state: MA\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    css: styles.css\n",
        "    html-math-method: katex\n",
        "    embed-resources: false\n",
        "    code-fold: true\n",
        "jupyter: python3\n",
        "execute:\n",
        "  eval: true\n",
        "---\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importing Necessary Libraries for Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3227,
      "metadata": {
        "id": "r3E6BfLihNAG"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf  # For downloading financial data\n",
        "import numpy as np      # For numerical operations\n",
        "import pandas as pd     # For data manipulation\n",
        "import requests # For downloading the API data\n",
        "import numpy as np \n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px # Import the Plotly Express module for interactive visualization\n",
        "import json\n",
        "import vectorbt as vbt\n",
        "from plotly.subplots import make_subplots\n",
        "import streamlit as st"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Collection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetch daily OHLCV data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3228,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PAqq4x7hhHQ",
        "outputId": "d2b18763-b874-471e-fd06-1cc141c449e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# Data for the TSLA, XLY, and SPY tickers is retrieved from the Yahoo Finance library, covering the period from January 1, 2019, \n",
        "# to March 5, 2025.\n",
        "tsla = yf.download('TSLA', start='2019-01-01', end='2025-03-05') \n",
        "xly = yf.download('XLY', start='2019-01-01', end='2025-03-05')\n",
        "spy = yf.download('SPY', start='2019-01-01', end='2025-03-05')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3229,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPlkUnohhxar",
        "outputId": "ffaa84e9-b819-44a7-f26e-e2a55a32d83e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1551 entries, 2019-01-02 to 2025-03-04\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   (Close, TSLA)   1551 non-null   float64\n",
            " 1   (High, TSLA)    1551 non-null   float64\n",
            " 2   (Low, TSLA)     1551 non-null   float64\n",
            " 3   (Open, TSLA)    1551 non-null   float64\n",
            " 4   (Volume, TSLA)  1551 non-null   int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 72.7 KB\n"
          ]
        }
      ],
      "source": [
        "# Displays a summary of the TSLA DataFrame, including column names, data types, non-null counts, and memory usage.\n",
        "tsla.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3230,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "MIzTpjBXhzbT",
        "outputId": "6e7bc69d-4e6d-421f-99e7-c4ad1fb3ad76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1551 entries, 2019-01-02 to 2025-03-04\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   (Close, XLY)   1551 non-null   float64\n",
            " 1   (High, XLY)    1551 non-null   float64\n",
            " 2   (Low, XLY)     1551 non-null   float64\n",
            " 3   (Open, XLY)    1551 non-null   float64\n",
            " 4   (Volume, XLY)  1551 non-null   int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 72.7 KB\n"
          ]
        }
      ],
      "source": [
        "# Displays a summary of the XLY DataFrame, including column names, data types, non-null counts, and memory usage.\n",
        "xly.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3231,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 1551 entries, 2019-01-02 to 2025-03-04\n",
            "Data columns (total 5 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   (Close, SPY)   1551 non-null   float64\n",
            " 1   (High, SPY)    1551 non-null   float64\n",
            " 2   (Low, SPY)     1551 non-null   float64\n",
            " 3   (Open, SPY)    1551 non-null   float64\n",
            " 4   (Volume, SPY)  1551 non-null   int64  \n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 72.7 KB\n"
          ]
        }
      ],
      "source": [
        "# Displays a summary of the SPY DataFrame, including column names, data types, non-null counts, and memory usage.\n",
        "spy.info()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetch sentiment scores from the API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3232,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defines the API endpoint URL for retrieving news sentiment data related to Tesla (TSLA) \n",
        "# from the Alpha Vantage service. The query specifies the function type, date range, result limit, \n",
        "# targeted ticker symbol, and a valid API key.\n",
        "###url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&time_from=20250101T0130&time_to=20250301T0130&limit=1000&tickers=TSLA&apikey=PNM5EHRALIOT1CKJ'\n",
        "\n",
        "# Sends a GET request to the specified URL to initiate the API call.\n",
        "###response = requests.get(url)\n",
        "\n",
        "# Evaluates whether the API call was successful based on the HTTP response status code.\n",
        "###if response.status_code == 200:\n",
        "    # Parses the JSON response and extracts the 'feed' section containing sentiment data.\n",
        "    ###sentiment_data = response.json()\n",
        "    \n",
        "    # Converts the extracted sentiment feed into a DataFrame for further analysis or visualization.\n",
        "   ### sentiment_df = pd.DataFrame(sentiment_data['feed']) \n",
        "    \n",
        "    # Displays the first five rows of the sentiment DataFrame to provide an overview of the retrieved content.\n",
        "    ###print(sentiment_df.head())\n",
        "###else:\n",
        "    # Prints an error message if the API request was unsuccessful.\n",
        "    ###print(\"API call failed:\", response.status_code)\n",
        "\n",
        "# Independently parses the full JSON response and prints its contents for inspection or debugging purposes.\n",
        "###sentiment_json = response.json()\n",
        "###print(sentiment_json)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indicator Calculation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute VI+ and VI-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3233,
      "metadata": {
        "id": "7vPyBW12ov2l"
      },
      "outputs": [],
      "source": [
        "# Defines a function to calculate the Vortex Indicator (VI) for a given DataFrame and ticker symbol.\n",
        "# The calculation uses a default lookback period of 14 days unless specified otherwise.\n",
        "def calculate_vortex(df, value, n=14):\n",
        "    # Extracts the high, low, and close price series for the specified ticker.\n",
        "    high = df[(\"High\", value)]\n",
        "    low = df[(\"Low\", value)]\n",
        "    close = df[(\"Close\", value)]\n",
        "\n",
        "    # Calculates the Vortex Movement values:\n",
        "    # VM+ = absolute difference between today's high and yesterday's low\n",
        "    # VM− = absolute difference between today's low and yesterday's high\n",
        "    vm_plus = abs(high - low.shift(1))     # |Today's High – Yesterday’s Low|\n",
        "    vm_minus = abs(low - high.shift(1))    # |Today's Low – Yesterday’s High|\n",
        "\n",
        "    # Computes the True Range (TR) as the maximum of:\n",
        "    # - High - Low\n",
        "    # - Absolute difference between High and Previous Close\n",
        "    # - Absolute difference between Low and Previous Close\n",
        "    tr = pd.concat([\n",
        "        high - low,\n",
        "        abs(high - close.shift(1)),\n",
        "        abs(low - close.shift(1))\n",
        "    ], axis=1).max(axis=1)\n",
        "\n",
        "    # Applies a rolling window to compute the n-period sum of VM+ and VM− values\n",
        "    # and the corresponding True Range values.\n",
        "    sum_vm_plus = vm_plus.rolling(window=n).sum()\n",
        "    sum_vm_minus = vm_minus.rolling(window=n).sum()\n",
        "    sum_tr = tr.rolling(window=n).sum()\n",
        "\n",
        "    # Calculates the Vortex Indicator components:\n",
        "    # VI+ = sum of VM+ over n periods divided by sum of TR over n periods\n",
        "    # VI− = sum of VM− over n periods divided by sum of TR over n periods\n",
        "    vi_plus = sum_vm_plus / sum_tr\n",
        "    vi_minus = sum_vm_minus / sum_tr\n",
        "\n",
        "    # Returns the VI+ and VI− series as output.\n",
        "    return vi_plus, vi_minus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3234,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "oh8LmXPFpDqO",
        "outputId": "d20f0c8a-1822-4449-8396-a9d5113f3deb"
      },
      "outputs": [],
      "source": [
        "# Calculates the Vortex Indicator values for TSLA and stores the results as new columns in the DataFrame.\n",
        "tsla['VI+'], tsla['VI-'] = calculate_vortex(tsla, 'TSLA')\n",
        "\n",
        "# Calculates the Vortex Indicator values for XLY and stores the results as new columns in the DataFrame.\n",
        "xly['VI+'], xly['VI-'] = calculate_vortex(xly, 'XLY')\n",
        "\n",
        "# Calculates the Vortex Indicator values for SPY and stores the results as new columns in the DataFrame.\n",
        "spy['VI+'], spy['VI-'] = calculate_vortex(spy, 'SPY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3235,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>Price</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>VI+</th>\n",
              "      <th>VI-</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticker</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>TSLA</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-02</th>\n",
              "      <td>20.674667</td>\n",
              "      <td>21.008667</td>\n",
              "      <td>19.920000</td>\n",
              "      <td>20.406668</td>\n",
              "      <td>174879000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-03</th>\n",
              "      <td>20.024000</td>\n",
              "      <td>20.626667</td>\n",
              "      <td>19.825333</td>\n",
              "      <td>20.466667</td>\n",
              "      <td>104478000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-04</th>\n",
              "      <td>21.179333</td>\n",
              "      <td>21.200001</td>\n",
              "      <td>20.181999</td>\n",
              "      <td>20.400000</td>\n",
              "      <td>110911500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-07</th>\n",
              "      <td>22.330667</td>\n",
              "      <td>22.449333</td>\n",
              "      <td>21.183332</td>\n",
              "      <td>21.448000</td>\n",
              "      <td>113268000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-08</th>\n",
              "      <td>22.356667</td>\n",
              "      <td>22.934000</td>\n",
              "      <td>21.801332</td>\n",
              "      <td>22.797333</td>\n",
              "      <td>105127500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-09</th>\n",
              "      <td>22.568666</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>22.098000</td>\n",
              "      <td>22.366667</td>\n",
              "      <td>81493500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-10</th>\n",
              "      <td>22.997999</td>\n",
              "      <td>23.025999</td>\n",
              "      <td>22.119333</td>\n",
              "      <td>22.293333</td>\n",
              "      <td>90846000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-11</th>\n",
              "      <td>23.150667</td>\n",
              "      <td>23.227333</td>\n",
              "      <td>22.584667</td>\n",
              "      <td>22.806000</td>\n",
              "      <td>75586500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-14</th>\n",
              "      <td>22.293333</td>\n",
              "      <td>22.833332</td>\n",
              "      <td>22.266666</td>\n",
              "      <td>22.825333</td>\n",
              "      <td>78709500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-15</th>\n",
              "      <td>22.962000</td>\n",
              "      <td>23.253332</td>\n",
              "      <td>22.299999</td>\n",
              "      <td>22.333332</td>\n",
              "      <td>90849000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-16</th>\n",
              "      <td>23.070000</td>\n",
              "      <td>23.466667</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>22.985332</td>\n",
              "      <td>70375500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-17</th>\n",
              "      <td>23.153999</td>\n",
              "      <td>23.433332</td>\n",
              "      <td>22.943333</td>\n",
              "      <td>23.080667</td>\n",
              "      <td>55150500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-18</th>\n",
              "      <td>20.150667</td>\n",
              "      <td>21.808666</td>\n",
              "      <td>19.982000</td>\n",
              "      <td>21.533333</td>\n",
              "      <td>362262000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-22</th>\n",
              "      <td>19.927999</td>\n",
              "      <td>20.533333</td>\n",
              "      <td>19.700001</td>\n",
              "      <td>20.321333</td>\n",
              "      <td>181000500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-23</th>\n",
              "      <td>19.172667</td>\n",
              "      <td>19.633333</td>\n",
              "      <td>18.779333</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>187950000</td>\n",
              "      <td>0.938520</td>\n",
              "      <td>0.946160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-24</th>\n",
              "      <td>19.434000</td>\n",
              "      <td>19.578667</td>\n",
              "      <td>18.618668</td>\n",
              "      <td>18.868668</td>\n",
              "      <td>120183000</td>\n",
              "      <td>0.937771</td>\n",
              "      <td>0.927867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-25</th>\n",
              "      <td>19.802668</td>\n",
              "      <td>19.901333</td>\n",
              "      <td>19.303333</td>\n",
              "      <td>19.625999</td>\n",
              "      <td>108744000</td>\n",
              "      <td>0.969095</td>\n",
              "      <td>0.953411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-28</th>\n",
              "      <td>19.758667</td>\n",
              "      <td>19.830667</td>\n",
              "      <td>19.183332</td>\n",
              "      <td>19.527332</td>\n",
              "      <td>96349500</td>\n",
              "      <td>0.886399</td>\n",
              "      <td>1.047633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-29</th>\n",
              "      <td>19.830667</td>\n",
              "      <td>19.903999</td>\n",
              "      <td>19.453333</td>\n",
              "      <td>19.684668</td>\n",
              "      <td>69325500</td>\n",
              "      <td>0.853825</td>\n",
              "      <td>1.081611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-30</th>\n",
              "      <td>20.584667</td>\n",
              "      <td>20.600000</td>\n",
              "      <td>19.899332</td>\n",
              "      <td>20.030001</td>\n",
              "      <td>168754500</td>\n",
              "      <td>0.859650</td>\n",
              "      <td>1.020518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Price           Close       High        Low       Open     Volume       VI+  \\\n",
              "Ticker           TSLA       TSLA       TSLA       TSLA       TSLA             \n",
              "Date                                                                          \n",
              "2019-01-02  20.674667  21.008667  19.920000  20.406668  174879000       NaN   \n",
              "2019-01-03  20.024000  20.626667  19.825333  20.466667  104478000       NaN   \n",
              "2019-01-04  21.179333  21.200001  20.181999  20.400000  110911500       NaN   \n",
              "2019-01-07  22.330667  22.449333  21.183332  21.448000  113268000       NaN   \n",
              "2019-01-08  22.356667  22.934000  21.801332  22.797333  105127500       NaN   \n",
              "2019-01-09  22.568666  22.900000  22.098000  22.366667   81493500       NaN   \n",
              "2019-01-10  22.997999  23.025999  22.119333  22.293333   90846000       NaN   \n",
              "2019-01-11  23.150667  23.227333  22.584667  22.806000   75586500       NaN   \n",
              "2019-01-14  22.293333  22.833332  22.266666  22.825333   78709500       NaN   \n",
              "2019-01-15  22.962000  23.253332  22.299999  22.333332   90849000       NaN   \n",
              "2019-01-16  23.070000  23.466667  22.900000  22.985332   70375500       NaN   \n",
              "2019-01-17  23.153999  23.433332  22.943333  23.080667   55150500       NaN   \n",
              "2019-01-18  20.150667  21.808666  19.982000  21.533333  362262000       NaN   \n",
              "2019-01-22  19.927999  20.533333  19.700001  20.321333  181000500       NaN   \n",
              "2019-01-23  19.172667  19.633333  18.779333  19.500000  187950000  0.938520   \n",
              "2019-01-24  19.434000  19.578667  18.618668  18.868668  120183000  0.937771   \n",
              "2019-01-25  19.802668  19.901333  19.303333  19.625999  108744000  0.969095   \n",
              "2019-01-28  19.758667  19.830667  19.183332  19.527332   96349500  0.886399   \n",
              "2019-01-29  19.830667  19.903999  19.453333  19.684668   69325500  0.853825   \n",
              "2019-01-30  20.584667  20.600000  19.899332  20.030001  168754500  0.859650   \n",
              "\n",
              "Price            VI-  \n",
              "Ticker                \n",
              "Date                  \n",
              "2019-01-02       NaN  \n",
              "2019-01-03       NaN  \n",
              "2019-01-04       NaN  \n",
              "2019-01-07       NaN  \n",
              "2019-01-08       NaN  \n",
              "2019-01-09       NaN  \n",
              "2019-01-10       NaN  \n",
              "2019-01-11       NaN  \n",
              "2019-01-14       NaN  \n",
              "2019-01-15       NaN  \n",
              "2019-01-16       NaN  \n",
              "2019-01-17       NaN  \n",
              "2019-01-18       NaN  \n",
              "2019-01-22       NaN  \n",
              "2019-01-23  0.946160  \n",
              "2019-01-24  0.927867  \n",
              "2019-01-25  0.953411  \n",
              "2019-01-28  1.047633  \n",
              "2019-01-29  1.081611  \n",
              "2019-01-30  1.020518  "
            ]
          },
          "execution_count": 3235,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Displays the first 20 rows of the TSLA DataFrame to provide an initial overview of its structure and content with the new function applied.\n",
        "tsla.head(20)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate Volume-Weighted Sentiment "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3236,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     sentiment_score   sentiment_label\n",
            "time_published                                        \n",
            "2025-03-01 00:00:18         0.225994  Somewhat-Bullish\n",
            "2025-02-28 20:33:00        -0.098739           Neutral\n",
            "2025-02-28 20:07:43        -0.041235           Neutral\n",
            "2025-02-28 20:07:36        -0.038786           Neutral\n",
            "2025-02-28 18:24:25         0.021961           Neutral\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 681 entries, 2025-03-01 00:00:18 to 2025-01-31 13:58:04\n",
            "Data columns (total 2 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   sentiment_score  681 non-null    float64\n",
            " 1   sentiment_label  681 non-null    object \n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 16.0+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Load the sentiment JSON file from local storage\n",
        "with open(\"TSLA_sentiment.json\", \"r\") as f:\n",
        "    sentiment_json = json.load(f)\n",
        "\n",
        "# Extract the \"feed\" list from the top-level JSON dictionary.\n",
        "# This section contains the array of sentiment articles or entries.\n",
        "sentiment_feed = sentiment_json.get(\"feed\", [])\n",
        "\n",
        "# Initialize an empty list to hold cleaned and structured sentiment data\n",
        "sentiment_data = []\n",
        "\n",
        "# Iterate through each item in the sentiment feed to extract relevant fields\n",
        "for item in sentiment_feed:\n",
        "    try:\n",
        "        sentiment_data.append({\n",
        "            # Convert the timestamp to pandas datetime for proper indexing\n",
        "            \"time_published\": pd.to_datetime(item[\"time_published\"]),\n",
        "            # Convert the sentiment score string to float\n",
        "            \"sentiment_score\": float(item[\"overall_sentiment_score\"]),\n",
        "            # Store the sentiment label (e.g., Positive, Neutral, Negative)\n",
        "            \"sentiment_label\": item[\"overall_sentiment_label\"],\n",
        "        })\n",
        "    except (KeyError, ValueError, TypeError):\n",
        "        # Skip malformed or incomplete entries that raise an error\n",
        "        continue\n",
        "\n",
        "# Convert the structured list of dictionaries into a pandas DataFrame\n",
        "sentiment_df = pd.DataFrame(sentiment_data)\n",
        "\n",
        "# Set the 'time_published' column as the DataFrame index to enable time-series operations\n",
        "sentiment_df.set_index(\"time_published\", inplace=True)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify content and structure\n",
        "print(sentiment_df.head())\n",
        "\n",
        "# Output a summary of the DataFrame structure, including column types and memory usage\n",
        "print(sentiment_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3237,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty list to store processed sentiment records\n",
        "sentiment_data = []\n",
        "\n",
        "# Iterate through each news item in the 'feed' section of the JSON object\n",
        "for news_item in sentiment_json.get(\"feed\", []):\n",
        "    # Append a dictionary with selected and transformed fields to the sentiment list\n",
        "    sentiment_data.append({\n",
        "        # Convert the time of publication to datetime format\n",
        "        \"time_published\": pd.to_datetime(news_item[\"time_published\"]),\n",
        "        # Extract the sentiment score (as-is; conversion to float may be handled separately if needed)\n",
        "        \"sentiment_score\": news_item[\"overall_sentiment_score\"],\n",
        "        # Extract the sentiment label (e.g., Positive, Neutral, Negative)\n",
        "        \"sentiment_label\": news_item[\"overall_sentiment_label\"],\n",
        "    })\n",
        "\n",
        "# Convert the list of dictionaries into a pandas DataFrame\n",
        "sentiment_data = pd.DataFrame(sentiment_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3238,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "680   2025-01-31 13:58:04\n",
              "679   2025-01-31 14:05:00\n",
              "678   2025-01-31 14:05:31\n",
              "677   2025-01-31 14:31:00\n",
              "676   2025-01-31 15:13:26\n",
              "              ...        \n",
              "4     2025-02-28 18:24:25\n",
              "3     2025-02-28 20:07:36\n",
              "2     2025-02-28 20:07:43\n",
              "1     2025-02-28 20:33:00\n",
              "0     2025-03-01 00:00:18\n",
              "Name: time_published, Length: 681, dtype: datetime64[ns]"
            ]
          },
          "execution_count": 3238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sort the DataFrame by publication time in ascending order for chronological analysis\n",
        "sentiment_data['time_published'].sort_values(ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3239,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the 'time_published' column to only retain the date portion (drop time-of-day)\n",
        "sentiment_data['time_published'] = sentiment_data['time_published'].dt.date"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3240,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter sentiment data to retain only those records that match dates present in the TSLA index\n",
        "sentiment_scores_filtered = sentiment_data[\n",
        "    pd.to_datetime(sentiment_data['time_published']).isin(tsla.index)\n",
        "]\n",
        "\n",
        "# Group the filtered data by publication date and calculate the average sentiment score per day\n",
        "sentiment_scores_filtered = sentiment_scores_filtered.groupby('time_published')['sentiment_score'].mean().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3241,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix the multi-level column issue by selecting the 'Volume' column and resetting its name\n",
        "tsla_volume = tsla[('Volume', 'TSLA')].rename('Volume')\n",
        "\n",
        "# Ensure the index of tsla_volume is a column and convert it to match the type of time_published\n",
        "tsla_volume = tsla_volume.reset_index()\n",
        "tsla_volume['Date'] = pd.to_datetime(tsla_volume['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3242,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert 'time_published' in the sentiment data to datetime to match volume data type\n",
        "sentiment_scores_filtered['time_published'] = pd.to_datetime(sentiment_scores_filtered['time_published'])\n",
        "\n",
        "# Perform an inner merge between sentiment scores and volume data based on matching dates\n",
        "merged_data = pd.merge(\n",
        "    tsla_volume,\n",
        "    sentiment_scores_filtered,\n",
        "    left_on='Date',\n",
        "    right_on='time_published',\n",
        "    how='inner'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3243,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute the weighted sentiment by multiplying raw sentiment by trading volume\n",
        "merged_data['Weighted_Sentiment'] = merged_data['Volume'] * merged_data['sentiment_score']\n",
        "\n",
        "# Calculate a 5-day rolling average of the weighted sentiment to smooth short-term noise\n",
        "merged_data['5_day_avg_sentiment'] = merged_data['Weighted_Sentiment'].rolling(window=5).mean()\n",
        "\n",
        "# Define a binary condition for when the average sentiment is positive\n",
        "merged_data['Buy_Condition'] = merged_data['5_day_avg_sentiment'] > 0\n",
        "\n",
        "# Normalize the rolling sentiment score by average volume to allow comparability across scales\n",
        "merged_data['5_day_avg_sentiment_norm'] = (\n",
        "    merged_data['5_day_avg_sentiment'] / merged_data['Volume'].mean()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3244,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Volume</th>\n",
              "      <th>time_published</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>Weighted_Sentiment</th>\n",
              "      <th>5_day_avg_sentiment</th>\n",
              "      <th>Buy_Condition</th>\n",
              "      <th>5_day_avg_sentiment_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-01-31</td>\n",
              "      <td>83568200</td>\n",
              "      <td>2025-01-31</td>\n",
              "      <td>0.194614</td>\n",
              "      <td>1.626354e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-02-03</td>\n",
              "      <td>93732100</td>\n",
              "      <td>2025-02-03</td>\n",
              "      <td>0.129243</td>\n",
              "      <td>1.211426e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-02-04</td>\n",
              "      <td>57072200</td>\n",
              "      <td>2025-02-04</td>\n",
              "      <td>0.173107</td>\n",
              "      <td>9.879602e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-02-05</td>\n",
              "      <td>57223300</td>\n",
              "      <td>2025-02-05</td>\n",
              "      <td>0.136874</td>\n",
              "      <td>7.832396e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-02-06</td>\n",
              "      <td>77918200</td>\n",
              "      <td>2025-02-06</td>\n",
              "      <td>0.118095</td>\n",
              "      <td>9.201782e+06</td>\n",
              "      <td>1.105832e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.132787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2025-02-07</td>\n",
              "      <td>70298300</td>\n",
              "      <td>2025-02-07</td>\n",
              "      <td>0.133871</td>\n",
              "      <td>9.410915e+06</td>\n",
              "      <td>9.687792e+06</td>\n",
              "      <td>True</td>\n",
              "      <td>0.116330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2025-02-10</td>\n",
              "      <td>77514900</td>\n",
              "      <td>2025-02-10</td>\n",
              "      <td>0.152754</td>\n",
              "      <td>1.184073e+07</td>\n",
              "      <td>9.633086e+06</td>\n",
              "      <td>True</td>\n",
              "      <td>0.115673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2025-02-11</td>\n",
              "      <td>118543400</td>\n",
              "      <td>2025-02-11</td>\n",
              "      <td>0.164455</td>\n",
              "      <td>1.949505e+07</td>\n",
              "      <td>1.155618e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.138766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2025-02-12</td>\n",
              "      <td>105382700</td>\n",
              "      <td>2025-02-12</td>\n",
              "      <td>0.147806</td>\n",
              "      <td>1.557620e+07</td>\n",
              "      <td>1.310494e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.157363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2025-02-13</td>\n",
              "      <td>89441500</td>\n",
              "      <td>2025-02-13</td>\n",
              "      <td>0.157124</td>\n",
              "      <td>1.405337e+07</td>\n",
              "      <td>1.407525e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.169015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2025-02-14</td>\n",
              "      <td>68277300</td>\n",
              "      <td>2025-02-14</td>\n",
              "      <td>0.148619</td>\n",
              "      <td>1.014733e+07</td>\n",
              "      <td>1.422254e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.170783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2025-02-18</td>\n",
              "      <td>51631700</td>\n",
              "      <td>2025-02-18</td>\n",
              "      <td>0.147289</td>\n",
              "      <td>7.604774e+06</td>\n",
              "      <td>1.337534e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.160610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2025-02-19</td>\n",
              "      <td>67094400</td>\n",
              "      <td>2025-02-19</td>\n",
              "      <td>0.142078</td>\n",
              "      <td>9.532654e+06</td>\n",
              "      <td>1.138286e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.136685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2025-02-20</td>\n",
              "      <td>45965400</td>\n",
              "      <td>2025-02-20</td>\n",
              "      <td>0.168076</td>\n",
              "      <td>7.725658e+06</td>\n",
              "      <td>9.812757e+06</td>\n",
              "      <td>True</td>\n",
              "      <td>0.117831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2025-02-21</td>\n",
              "      <td>74058600</td>\n",
              "      <td>2025-02-21</td>\n",
              "      <td>0.159107</td>\n",
              "      <td>1.178322e+07</td>\n",
              "      <td>9.358728e+06</td>\n",
              "      <td>True</td>\n",
              "      <td>0.112379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2025-02-24</td>\n",
              "      <td>76052300</td>\n",
              "      <td>2025-02-24</td>\n",
              "      <td>0.110839</td>\n",
              "      <td>8.429546e+06</td>\n",
              "      <td>9.015171e+06</td>\n",
              "      <td>True</td>\n",
              "      <td>0.108253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2025-02-25</td>\n",
              "      <td>134228800</td>\n",
              "      <td>2025-02-25</td>\n",
              "      <td>0.071949</td>\n",
              "      <td>9.657658e+06</td>\n",
              "      <td>9.425748e+06</td>\n",
              "      <td>True</td>\n",
              "      <td>0.113184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2025-02-26</td>\n",
              "      <td>100118300</td>\n",
              "      <td>2025-02-26</td>\n",
              "      <td>0.142984</td>\n",
              "      <td>1.431534e+07</td>\n",
              "      <td>1.038228e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.124670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2025-02-27</td>\n",
              "      <td>101748200</td>\n",
              "      <td>2025-02-27</td>\n",
              "      <td>0.174702</td>\n",
              "      <td>1.777563e+07</td>\n",
              "      <td>1.239228e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.148806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2025-02-28</td>\n",
              "      <td>115697000</td>\n",
              "      <td>2025-02-28</td>\n",
              "      <td>0.115746</td>\n",
              "      <td>1.339148e+07</td>\n",
              "      <td>1.271393e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.152668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date     Volume time_published  sentiment_score  Weighted_Sentiment  \\\n",
              "0  2025-01-31   83568200     2025-01-31         0.194614        1.626354e+07   \n",
              "1  2025-02-03   93732100     2025-02-03         0.129243        1.211426e+07   \n",
              "2  2025-02-04   57072200     2025-02-04         0.173107        9.879602e+06   \n",
              "3  2025-02-05   57223300     2025-02-05         0.136874        7.832396e+06   \n",
              "4  2025-02-06   77918200     2025-02-06         0.118095        9.201782e+06   \n",
              "5  2025-02-07   70298300     2025-02-07         0.133871        9.410915e+06   \n",
              "6  2025-02-10   77514900     2025-02-10         0.152754        1.184073e+07   \n",
              "7  2025-02-11  118543400     2025-02-11         0.164455        1.949505e+07   \n",
              "8  2025-02-12  105382700     2025-02-12         0.147806        1.557620e+07   \n",
              "9  2025-02-13   89441500     2025-02-13         0.157124        1.405337e+07   \n",
              "10 2025-02-14   68277300     2025-02-14         0.148619        1.014733e+07   \n",
              "11 2025-02-18   51631700     2025-02-18         0.147289        7.604774e+06   \n",
              "12 2025-02-19   67094400     2025-02-19         0.142078        9.532654e+06   \n",
              "13 2025-02-20   45965400     2025-02-20         0.168076        7.725658e+06   \n",
              "14 2025-02-21   74058600     2025-02-21         0.159107        1.178322e+07   \n",
              "15 2025-02-24   76052300     2025-02-24         0.110839        8.429546e+06   \n",
              "16 2025-02-25  134228800     2025-02-25         0.071949        9.657658e+06   \n",
              "17 2025-02-26  100118300     2025-02-26         0.142984        1.431534e+07   \n",
              "18 2025-02-27  101748200     2025-02-27         0.174702        1.777563e+07   \n",
              "19 2025-02-28  115697000     2025-02-28         0.115746        1.339148e+07   \n",
              "\n",
              "    5_day_avg_sentiment  Buy_Condition  5_day_avg_sentiment_norm  \n",
              "0                   NaN          False                       NaN  \n",
              "1                   NaN          False                       NaN  \n",
              "2                   NaN          False                       NaN  \n",
              "3                   NaN          False                       NaN  \n",
              "4          1.105832e+07           True                  0.132787  \n",
              "5          9.687792e+06           True                  0.116330  \n",
              "6          9.633086e+06           True                  0.115673  \n",
              "7          1.155618e+07           True                  0.138766  \n",
              "8          1.310494e+07           True                  0.157363  \n",
              "9          1.407525e+07           True                  0.169015  \n",
              "10         1.422254e+07           True                  0.170783  \n",
              "11         1.337534e+07           True                  0.160610  \n",
              "12         1.138286e+07           True                  0.136685  \n",
              "13         9.812757e+06           True                  0.117831  \n",
              "14         9.358728e+06           True                  0.112379  \n",
              "15         9.015171e+06           True                  0.108253  \n",
              "16         9.425748e+06           True                  0.113184  \n",
              "17         1.038228e+07           True                  0.124670  \n",
              "18         1.239228e+07           True                  0.148806  \n",
              "19         1.271393e+07           True                  0.152668  "
            ]
          },
          "execution_count": 3244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "merged_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Derive ATR (10) for Volatility Adjustments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3245,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Close_TSLA     ATR_10   atr_pct  position_size\n",
            "Date                                                      \n",
            "2025-02-19  360.559998  16.703000  0.046325          0.005\n",
            "2025-02-20  354.399994  16.464999  0.046459          0.005\n",
            "2025-02-21  337.799988  17.021997  0.050391          0.005\n",
            "2025-02-24  330.529999  16.770996  0.050740          0.005\n",
            "2025-02-25  302.799988  18.879996  0.062351          0.005\n",
            "2025-02-26  290.799988  18.412994  0.063318          0.005\n",
            "2025-02-27  281.950012  18.257996  0.064756          0.005\n",
            "2025-02-28  292.980011  18.067996  0.061670          0.005\n",
            "2025-03-03  284.649994  19.281998  0.067739          0.005\n",
            "2025-03-04  272.040009  20.654996  0.075926          0.005\n"
          ]
        }
      ],
      "source": [
        "# Flatten MultiIndex columns if present to simplify DataFrame operations\n",
        "tsla.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) else col\n",
        "    for col in tsla.columns\n",
        "]\n",
        "\n",
        "# Calculate the previous closing price to support True Range computation\n",
        "tsla[\"prev_close\"] = tsla[\"Close_TSLA\"].shift(1)\n",
        "\n",
        "# Compute three True Range variations used in ATR calculation\n",
        "tsla[\"tr1\"] = tsla[\"High_TSLA\"] - tsla[\"Low_TSLA\"]\n",
        "tsla[\"tr2\"] = abs(tsla[\"High_TSLA\"] - tsla[\"prev_close\"])\n",
        "tsla[\"tr3\"] = abs(tsla[\"Low_TSLA\"] - tsla[\"prev_close\"])\n",
        "\n",
        "# Derive the True Range (TR) as the maximum of the three variants\n",
        "tsla[\"true_range\"] = tsla[[\"tr1\", \"tr2\", \"tr3\"]].max(axis=1)\n",
        "\n",
        "# Compute the 10-day Average True Range (ATR) to measure market volatility\n",
        "tsla[\"ATR_10\"] = tsla[\"true_range\"].rolling(window=10).mean()\n",
        "\n",
        "# Calculate ATR as a percentage of the current closing price to normalize volatility\n",
        "tsla[\"atr_pct\"] = tsla[\"ATR_10\"] / tsla[\"Close_TSLA\"]\n",
        "\n",
        "# Define a function to assign position size based on volatility levels\n",
        "def position_size(row):\n",
        "    if row[\"atr_pct\"] < 0.03:\n",
        "        return 0.01  # Allocate 1% of capital for low-volatility conditions\n",
        "    else:\n",
        "        return 0.005  # Allocate 0.5% of capital for high-volatility conditions\n",
        "\n",
        "# Apply the position size function across all rows\n",
        "tsla[\"position_size\"] = tsla.apply(position_size, axis=1)\n",
        "\n",
        "# Display the latest 10 rows with selected indicators for inspection\n",
        "print(tsla[[\"Close_TSLA\", \"ATR_10\", \"atr_pct\", \"position_size\"]].tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3246,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Create ATR% over time chart ===\n",
        "fig = px.line(\n",
        "    tsla,\n",
        "    x=tsla.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"ATR% Over Time\"\n",
        ")\n",
        "\n",
        "# === Add 3% horizontal reference line ===\n",
        "fig.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# === Display in Streamlit ===\n",
        "st.subheader(\"TSLA ATR% Over Time\")\n",
        "st.plotly_chart(fig, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3247,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"figures/atr%_5y.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x30b4deb50>"
            ]
          },
          "execution_count": 3247,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import IFrame\n",
        "\n",
        "IFrame(src='figures/atr%_5y.html', width='100%', height='600px')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The chart illustrates the historical volatility of TSLA, measured by the Average True Range (ATR) as a percentage of the closing price. Periods where the ATR% falls below the dotted green line at 3% indicate low volatility, which is typically associated with more stable market conditions. In contrast, noticeable spikes—such as those seen in 2020 and 2021—reflect periods of heightened volatility. More recently, ATR% values appear to remain closer to or slightly above the low-volatility threshold, suggesting relatively calmer market behavior compared to earlier years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3248,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3248,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Filter TSLA data for 2025 only ===\n",
        "tsla_2025 = tsla[tsla.index.year == 2025]\n",
        "\n",
        "# === Create the line chart for ATR% ===\n",
        "tsla_atr_fig = px.line(\n",
        "    tsla_2025,\n",
        "    x=tsla_2025.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"ATR% Over Time (2025 Only)\"\n",
        ")\n",
        "\n",
        "# === Add low-volatility threshold line ===\n",
        "tsla_atr_fig.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# === Display in Streamlit ===\n",
        "st.subheader(\"TSLA ATR% – 2025\")\n",
        "st.plotly_chart(tsla_atr_fig, use_container_width=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The chart displays ATR% for TSLA during 2025, reflecting how the stock's volatility has evolved since the start of the year. While ATR% began above the 7% mark in early January, it gradually declined and remained mostly between 4% and 6% throughout February. Although volatility did not breach the low-volatility threshold of 3%, the dip toward that level suggests a period of relative calm. Toward early March, ATR% showed a clear upward trend, indicating a potential resurgence in market volatility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3249,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buy signals: 857\n",
            "Sell signals: 680\n"
          ]
        }
      ],
      "source": [
        "# Create Buy Signal\n",
        "tsla['Buy_Signal'] = tsla['VI+_'] > tsla['VI-_']  # Vortex crossover\n",
        "\n",
        "# Create Sell Signal (basic)\n",
        "tsla['Sell_Signal'] = tsla['VI-_'] > tsla['VI+_']\n",
        "\n",
        "# Initialize the position tracking column with 0 (no active position)\n",
        "tsla['Position'] = 0\n",
        "\n",
        "# Initialize a variable to store the peak price during a position for trailing stop logic\n",
        "peak_price = 0\n",
        "\n",
        "# Iterate through the dataset starting from index 1 to access previous values\n",
        "for i in range(1, len(tsla)):\n",
        "\n",
        "    # Entry condition: enter a position if a buy signal is present\n",
        "    if tsla['Buy_Signal'].iloc[i]:\n",
        "        tsla.at[tsla.index[i], 'Position'] = 1  # Mark entry into a position\n",
        "        peak_price = tsla['Close_TSLA'].iloc[i]  # Record the entry price as initial peak\n",
        "\n",
        "    # If already in position, check for exit condition using trailing stop\n",
        "    elif tsla['Position'].iloc[i - 1] == 1:\n",
        "        current_price = tsla['Close_TSLA'].iloc[i]  # Current closing price\n",
        "        peak_price = max(peak_price, current_price)  # Update peak price if current exceeds previous\n",
        "        drawdown = (peak_price - current_price) / peak_price  # Compute drawdown from peak\n",
        "\n",
        "        # Exit condition: drawdown exceeds 3%\n",
        "        if drawdown >= 0.03:\n",
        "            tsla.at[tsla.index[i], 'Sell_Signal'] = True  # Trigger a sell signal\n",
        "            tsla.at[tsla.index[i], 'Position'] = 0        # Exit position\n",
        "        else:\n",
        "            tsla.at[tsla.index[i], 'Position'] = 1        # Maintain position\n",
        "\n",
        "# Display the total number of buy and sell signals generated across the dataset\n",
        "print(\"Buy signals:\", tsla['Buy_Signal'].sum())\n",
        "print(\"Sell signals:\", tsla['Sell_Signal'].sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3250,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Create figure ===\n",
        "tsla_basic_signals_fig = go.Figure()\n",
        "\n",
        "# === Plot TSLA closing price ===\n",
        "tsla_basic_signals_fig.add_trace(go.Scatter(\n",
        "    x=tsla.index,\n",
        "    y=tsla['Close_TSLA'],\n",
        "    mode='lines',\n",
        "    name='TSLA Price',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# === Buy Signal markers ===\n",
        "tsla_basic_signals_fig.add_trace(go.Scatter(\n",
        "    x=tsla[tsla['Buy_Signal']].index,\n",
        "    y=tsla[tsla['Buy_Signal']]['Close_TSLA'],\n",
        "    mode='markers',\n",
        "    name='Buy Signal',\n",
        "    marker=dict(symbol='triangle-up', size=10, color='green')\n",
        "))\n",
        "\n",
        "# === Sell Signal markers ===\n",
        "tsla_basic_signals_fig.add_trace(go.Scatter(\n",
        "    x=tsla[tsla['Sell_Signal']].index,\n",
        "    y=tsla[tsla['Sell_Signal']]['Close_TSLA'],\n",
        "    mode='markers',\n",
        "    name='Sell Signal',\n",
        "    marker=dict(symbol='triangle-down', size=10, color='red')\n",
        "))\n",
        "\n",
        "# === Layout styling ===\n",
        "tsla_basic_signals_fig.update_layout(\n",
        "    title='TSLA Buy & Sell Signals',\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "# === Display in Streamlit ===\n",
        "st.subheader(\"TSLA Price with Buy & Sell Signals\")\n",
        "st.plotly_chart(tsla_basic_signals_fig, use_container_width=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The chart illustrates the closing price of Tesla stock over time, with overlaid trading signals generated by the strategy. Green upward triangles represent buy signals, while red downward triangles mark sell signals. These signals are distributed throughout periods of both rising and falling prices, reflecting how the algorithm dynamically enters and exits positions based on market conditions. Clusters of signals during high-volatility periods—such as 2020, 2021, and early 2025—indicate frequent entries and exits, whereas more stable phases show fewer trades."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3251,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buy signals: 80\n",
            "Sell signals: 80\n",
            "Aggressive entries: 5\n",
            "Conservative entries: 75\n"
          ]
        }
      ],
      "source": [
        "# Calculate ATR as a percentage of the closing price to normalize volatility\n",
        "tsla['atr_pct'] = tsla['ATR_10'] / tsla['Close_TSLA']\n",
        "\n",
        "# Define Vortex Indicator crossover signals:\n",
        "# - VI_Cross_Up: Identifies when VI+ crosses above VI− (potential bullish signal)\n",
        "# - VI_Cross_Down: Identifies when VI− crosses above VI+ (potential bearish signal)\n",
        "tsla['VI_Cross_Up'] = (tsla['VI+_'] > tsla['VI-_']) & (tsla['VI+_'].shift(1) <= tsla['VI-_'].shift(1))\n",
        "tsla['VI_Cross_Down'] = (tsla['VI-_'] > tsla['VI+_']) & (tsla['VI-_'].shift(1) <= tsla['VI+_'].shift(1))\n",
        "\n",
        "# Initialize signal and state columns\n",
        "tsla['Buy_Signal'] = False          # Flag for buy signal\n",
        "tsla['Sell_Signal'] = False         # Flag for sell signal\n",
        "tsla['Position'] = 0                # Position state: 1 = in position, 0 = no position\n",
        "tsla['Entry_Type'] = None           # Strategy classification: 'aggressive' or 'conservative'\n",
        "\n",
        "# Initialize control variables for trailing stop and price tracking\n",
        "in_position = False                 # Boolean flag for current position state\n",
        "peak_price = 0                      # Highest price observed during an open position\n",
        "\n",
        "# Iterate through the DataFrame to simulate trading logic based on Vortex signals and volatility\n",
        "for i in range(1, len(tsla)):\n",
        "    row = tsla.iloc[i]\n",
        "    idx = tsla.index[i]\n",
        "\n",
        "    # Buy condition: Enter a new position if VI_Cross_Up occurs and no current position is held\n",
        "    if not in_position and row['VI_Cross_Up']:\n",
        "        tsla.at[idx, 'Buy_Signal'] = True\n",
        "        tsla.at[idx, 'Position'] = 1\n",
        "        in_position = True\n",
        "        peak_price = row['Close_TSLA']\n",
        "\n",
        "        # Classify entry type based on volatility threshold\n",
        "        if row['atr_pct'] < 0.03:\n",
        "            tsla.at[idx, 'Entry_Type'] = 'aggressive'\n",
        "        else:\n",
        "            tsla.at[idx, 'Entry_Type'] = 'conservative'\n",
        "\n",
        "    # While in position, evaluate for trailing stop or VI_Cross_Down exit condition\n",
        "    elif in_position:\n",
        "        current_price = row['Close_TSLA']\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        # Sell condition: Exit if drawdown exceeds 3% or VI_Cross_Down occurs\n",
        "        if drawdown >= 0.03 or row['VI_Cross_Down']:\n",
        "            tsla.at[idx, 'Sell_Signal'] = True\n",
        "            tsla.at[idx, 'Position'] = 0\n",
        "            in_position = False\n",
        "        else:\n",
        "            tsla.at[idx, 'Position'] = 1  # Maintain position\n",
        "\n",
        "# Output the total count of each type of signal and entry classification\n",
        "print(\"Buy signals:\", tsla['Buy_Signal'].sum())\n",
        "print(\"Sell signals:\", tsla['Sell_Signal'].sum())\n",
        "print(\"Aggressive entries:\", (tsla['Entry_Type'] == 'aggressive').sum())\n",
        "print(\"Conservative entries:\", (tsla['Entry_Type'] == 'conservative').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3252,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3252,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# === Create an empty figure ===\n",
        "tsla_signals_fig = go.Figure()\n",
        "\n",
        "# === Plot TSLA closing price ===\n",
        "tsla_signals_fig.add_trace(go.Scatter(\n",
        "    x=tsla.index,\n",
        "    y=tsla['Close_TSLA'],\n",
        "    mode='lines',\n",
        "    name='TSLA Price',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# === Aggressive buy signals ===\n",
        "tsla_signals_fig.add_trace(go.Scatter(\n",
        "    x=tsla[(tsla['Buy_Signal']) & (tsla['Entry_Type'] == 'aggressive')].index,\n",
        "    y=tsla[(tsla['Buy_Signal']) & (tsla['Entry_Type'] == 'aggressive')]['Close_TSLA'],\n",
        "    mode='markers',\n",
        "    name='Buy (Aggressive)',\n",
        "    marker=dict(symbol='triangle-up', color='limegreen', size=10)\n",
        "))\n",
        "\n",
        "# === Conservative buy signals ===\n",
        "tsla_signals_fig.add_trace(go.Scatter(\n",
        "    x=tsla[(tsla['Buy_Signal']) & (tsla['Entry_Type'] == 'conservative')].index,\n",
        "    y=tsla[(tsla['Buy_Signal']) & (tsla['Entry_Type'] == 'conservative')]['Close_TSLA'],\n",
        "    mode='markers',\n",
        "    name='Buy (Conservative)',\n",
        "    marker=dict(symbol='triangle-up', color='green', size=10)\n",
        "))\n",
        "\n",
        "# === Sell signals ===\n",
        "tsla_signals_fig.add_trace(go.Scatter(\n",
        "    x=tsla[tsla['Sell_Signal']].index,\n",
        "    y=tsla[tsla['Sell_Signal']]['Close_TSLA'],\n",
        "    mode='markers',\n",
        "    name='Sell Signal',\n",
        "    marker=dict(symbol='triangle-down', color='red', size=10)\n",
        "))\n",
        "\n",
        "# === Layout configuration ===\n",
        "tsla_signals_fig.update_layout(\n",
        "    title=\"TSLA Buy/Sell Signals Over Time\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Price (USD)\",\n",
        "    template=\"plotly_white\",\n",
        "    height=600\n",
        ")\n",
        "\n",
        "# === Streamlit display ===\n",
        "st.subheader(\"TSLA Buy/Sell Signal Chart\")\n",
        "st.plotly_chart(tsla_signals_fig, use_container_width=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The chart displays the historical closing price of Tesla (TSLA) stock alongside algorithmically generated buy and sell signals. The blue line represents TSLA's closing price, while the green upward-pointing triangles indicate buy entries—distinguished by lime green for aggressive entries (lower volatility) and dark green for conservative entries (higher volatility). Red downward-pointing triangles represent sell signals.\n",
        "\n",
        "The buy signals are generally aligned with upward momentum, and sell signals frequently follow periods of short-term retracement or heightened volatility. The system shows particularly dense activity around highly volatile phases, such as mid-2020 to early 2022, capturing many entries and exits. In contrast, during more stable periods, the signals are more spaced out. Overall, the plot provides a clear visual assessment of how the strategy adapts dynamically to changing market conditions by modulating its entries based on volatility and exiting with protective trailing logic."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tesla Analysis Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3253,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsla_signals = tsla.reset_index()[['Date', 'VI_Cross_Up', 'VI_Cross_Down', 'atr_pct', 'Close_TSLA']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3254,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_data = pd.merge(merged_data, tsla, on='Date', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3255,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buy signals: 18\n",
            "Sell signals: 1\n",
            "Aggressive entries: 0\n",
            "Conservative entries: 18\n"
          ]
        }
      ],
      "source": [
        "# Calculate ATR percentage\n",
        "merged_data['atr_pct'] = merged_data['ATR_10'] / merged_data['Close_TSLA']\n",
        "\n",
        "# Vortex crossover logic\n",
        "merged_data['VI_Cross_Up'] = (merged_data['VI+_'] > merged_data['VI-_']) & (merged_data['VI+_'].shift(1) <= merged_data['VI-_'].shift(1))\n",
        "merged_data['VI_Cross_Down'] = (merged_data['VI-_'] > merged_data['VI+_']) & (merged_data['VI-_'].shift(1) <= merged_data['VI+_'].shift(1))\n",
        "\n",
        "# Initialize signal & state columns\n",
        "merged_data['Buy_Signal'] = False\n",
        "merged_data['Sell_Signal'] = False\n",
        "merged_data['Position'] = 0\n",
        "merged_data['Entry_Type'] = None  # aggressive/conservative\n",
        "\n",
        "# Trailing stop logic variables\n",
        "in_position = False\n",
        "peak_price = 0\n",
        "\n",
        "for i in range(1, len(merged_data)):\n",
        "    row = merged_data.iloc[i]\n",
        "    idx = merged_data.index[i]\n",
        "    # Buy condition\n",
        "    if not in_position or row['VI_Cross_Up'] or row['5_day_avg_sentiment_norm']>0:\n",
        "        merged_data.at[idx, 'Buy_Signal'] = True\n",
        "        merged_data.at[idx, 'Position'] = 1\n",
        "        in_position = True\n",
        "        peak_price = row['Close_TSLA']\n",
        "\n",
        "        # Entry Type: aggressive if ATR < 3%, else conservative\n",
        "        if row['atr_pct'] < 0.03:\n",
        "            merged_data.at[idx, 'Entry_Type'] = 'aggressive'\n",
        "        else:\n",
        "            merged_data.at[idx, 'Entry_Type'] = 'conservative'\n",
        "\n",
        "    # While in position, check for trailing stop or VI cross down\n",
        "    elif in_position:\n",
        "        current_price = row['Close_TSLA']\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        if drawdown >= 0.03 or row['VI_Cross_Down']:\n",
        "            merged_data.at[idx, 'Sell_Signal'] = True\n",
        "            merged_data.at[idx, 'Position'] = 0\n",
        "            in_position = False\n",
        "        else:\n",
        "            merged_data.at[idx, 'Position'] = 1\n",
        "\n",
        "# Show result counts\n",
        "print(\"Buy signals:\", merged_data['Buy_Signal'].sum())\n",
        "print(\"Sell signals:\", merged_data['Sell_Signal'].sum())\n",
        "print(\"Aggressive entries:\", (merged_data['Entry_Type'] == 'aggressive').sum())\n",
        "print(\"Conservative entries:\", (merged_data['Entry_Type'] == 'conservative').sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3256,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ensure 'Date' is datetime\n",
        "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
        "\n",
        "# Create unique figure name\n",
        "sentiment_atr_fig = go.Figure()\n",
        "\n",
        "# 5-Day Avg Sentiment\n",
        "sentiment_atr_fig.add_trace(go.Scatter(\n",
        "    x=merged_data['Date'],\n",
        "    y=merged_data['5_day_avg_sentiment_norm'],\n",
        "    mode='lines+markers',\n",
        "    name='5-Day Avg Sentiment',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# ATR %\n",
        "sentiment_atr_fig.add_trace(go.Scatter(\n",
        "    x=merged_data['Date'],\n",
        "    y=merged_data['atr_pct'],\n",
        "    mode='lines+markers',\n",
        "    name='ATR %',\n",
        "    yaxis='y2',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Buy Signal Markers\n",
        "sentiment_atr_fig.add_trace(go.Scatter(\n",
        "    x=merged_data.loc[merged_data['Buy_Signal'], 'Date'],\n",
        "    y=merged_data.loc[merged_data['Buy_Signal'], '5_day_avg_sentiment_norm'],\n",
        "    mode='markers',\n",
        "    marker=dict(color='green', size=10, symbol='star'),\n",
        "    name='Buy Signal'\n",
        "))\n",
        "\n",
        "# Layout\n",
        "sentiment_atr_fig.update_layout(\n",
        "    title='5-Day Sentiment vs ATR % (with Buy Signals)',\n",
        "    xaxis_title='Date',\n",
        "    yaxis=dict(title='5-Day Avg Sentiment'),\n",
        "    yaxis2=dict(title='ATR %', overlaying='y', side='right'),\n",
        "    legend=dict(x=0.01, y=0.99),\n",
        "    height=500,\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "# Streamlit display\n",
        "st.plotly_chart(sentiment_atr_fig, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3257,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Capital: $99,898.47\n",
            "Total Return: $-101.53\n",
            "Total Trades: 1\n",
            "Average Profit per Trade: $11.12\n"
          ]
        }
      ],
      "source": [
        "# Initialize portfolio variables\n",
        "capital = 100000                   # Starting capital for the simulation\n",
        "in_position = False               # Flag indicating whether a position is currently held\n",
        "entry_price = 0                   # Entry price of the current position\n",
        "position_value = 0                # Dollar value allocated to the position\n",
        "cash = capital                    # Available cash (initially equal to capital)\n",
        "returns = []                      # List to store profit/loss for each trade\n",
        "\n",
        "# Iterate over the dataset to simulate trading\n",
        "for i in range(len(merged_data)):\n",
        "    row = merged_data.iloc[i]\n",
        "\n",
        "    # ==== Buy Logic ====\n",
        "    if row['Buy_Signal'] and not in_position:\n",
        "        position_size = row['position_size']             # Fraction of capital to allocate\n",
        "        position_value = cash * position_size            # Calculate how much capital to invest\n",
        "        entry_price = row['Close_TSLA']                  # Record entry price\n",
        "        shares_bought = position_value / entry_price     # Calculate number of shares to buy\n",
        "        cash -= position_value                           # Deduct invested capital from cash\n",
        "        in_position = True                               # Update position flag\n",
        "\n",
        "    # ==== Sell Logic ====\n",
        "    elif row['Sell_Signal'] and in_position:\n",
        "        exit_price = row['Close_TSLA']                   # Get the exit price\n",
        "        proceeds = shares_bought * exit_price            # Calculate proceeds from sale\n",
        "        profit = proceeds - position_value               # Profit = proceeds - initial investment\n",
        "        cash += proceeds                                 # Add proceeds back to cash\n",
        "        returns.append(profit)                           # Record trade return\n",
        "        in_position = False                              # Reset position state\n",
        "        position_value = 0                               # Clear position value\n",
        "        entry_price = 0                                  # Reset entry price\n",
        "\n",
        "# ==== Final Capital Calculation ====\n",
        "# If still holding a position, add unrealized value to cash\n",
        "final_value = cash + (shares_bought * row['Close_TSLA'] if in_position else 0)\n",
        "total_return = final_value - capital                    # Net profit/loss from strategy\n",
        "\n",
        "# ==== Print Performance Metrics ====\n",
        "print(f\"Final Capital: ${final_value:,.2f}\")\n",
        "print(f\"Total Return: ${total_return:.2f}\")\n",
        "print(f\"Total Trades: {len(returns)}\")\n",
        "print(f\"Average Profit per Trade: ${np.mean(returns):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3258,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure index is datetime and 'Close_TSLA' exists\n",
        "price = tsla['Close_TSLA']\n",
        "\n",
        "# Generate entries and exits from your signals\n",
        "entries = tsla['Buy_Signal']\n",
        "exits = tsla['Sell_Signal']\n",
        "\n",
        "# Create portfolio\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    size=np.nan,  # Let it auto-calculate position size if fixed capital\n",
        "    init_cash=100_000,\n",
        "    fees=0.001,  # 0.1% per trade\n",
        "    slippage=0.0005  # Optional\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3259,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start                         2019-01-02 00:00:00\n",
            "End                           2025-03-04 00:00:00\n",
            "Period                                       1551\n",
            "Start Value                              100000.0\n",
            "End Value                                100000.0\n",
            "Total Return [%]                              0.0\n",
            "Benchmark Return [%]                  1215.813231\n",
            "Max Gross Exposure [%]                        0.0\n",
            "Total Fees Paid                               0.0\n",
            "Max Drawdown [%]                              NaN\n",
            "Max Drawdown Duration                         NaN\n",
            "Total Trades                                    0\n",
            "Total Closed Trades                             0\n",
            "Total Open Trades                               0\n",
            "Open Trade PnL                                0.0\n",
            "Win Rate [%]                                  NaN\n",
            "Best Trade [%]                                NaN\n",
            "Worst Trade [%]                               NaN\n",
            "Avg Winning Trade [%]                         NaN\n",
            "Avg Losing Trade [%]                          NaN\n",
            "Avg Winning Trade Duration                    NaN\n",
            "Avg Losing Trade Duration                     NaN\n",
            "Profit Factor                                 NaN\n",
            "Expectancy                                    NaN\n",
            "dtype: object\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary stats\n",
        "print(portfolio.stats())\n",
        "\n",
        "st.subheader(\"TSLA Performance 1\")\n",
        "tsla_portfolio_fig = portfolio.plot()\n",
        "st.plotly_chart(tsla_portfolio_fig, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3260,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "80\n",
            "80\n"
          ]
        }
      ],
      "source": [
        "print(tsla['Buy_Signal'].sum())  # Should be > 0\n",
        "print(tsla['Sell_Signal'].sum())  # Should also be > 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3261,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsla = tsla.dropna(subset=['Close_TSLA'])\n",
        "entries = tsla['Buy_Signal'].astype(bool)\n",
        "exits = tsla['Sell_Signal'].astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3262,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start                         2019-01-02 00:00:00\n",
            "End                           2025-03-04 00:00:00\n",
            "Period                                       1551\n",
            "Start Value                              100000.0\n",
            "End Value                                100000.0\n",
            "Total Return [%]                              0.0\n",
            "Benchmark Return [%]                  1215.813231\n",
            "Max Gross Exposure [%]                        0.0\n",
            "Total Fees Paid                               0.0\n",
            "Max Drawdown [%]                              NaN\n",
            "Max Drawdown Duration                         NaN\n",
            "Total Trades                                    0\n",
            "Total Closed Trades                             0\n",
            "Total Open Trades                               0\n",
            "Open Trade PnL                                0.0\n",
            "Win Rate [%]                                  NaN\n",
            "Best Trade [%]                                NaN\n",
            "Worst Trade [%]                               NaN\n",
            "Avg Winning Trade [%]                         NaN\n",
            "Avg Losing Trade [%]                          NaN\n",
            "Avg Winning Trade Duration                    NaN\n",
            "Avg Losing Trade Duration                     NaN\n",
            "Profit Factor                                 NaN\n",
            "Expectancy                                    NaN\n",
            "dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3262,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "price = tsla['Close_TSLA']\n",
        "portfolio_tsla = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    init_cash=100_000,\n",
        "    fees=0.001\n",
        ")\n",
        "\n",
        "print(portfolio.stats())\n",
        "st.subheader(\"TSLA Portfolio Performance\")\n",
        "st.plotly_chart(portfolio_tsla.plot(), use_container_width=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The backtest results show that while the strategy achieved a total return of approximately 62.76%, it significantly underperformed compared to a simple buy-and-hold strategy on TSLA, which yielded a 1215.81% return. The strategy executed 80 trades with a low win rate of 32.5%, indicating that most trades were unprofitable. Although it had a few strong winners, the average profit per trade was marginal, with a profit factor of 1.19. Additionally, the portfolio experienced a substantial maximum drawdown of 55.35% and a prolonged recovery period lasting two years, signaling high risk. Visuals further confirm that many trades resulted in small losses or gains, with only a few notable profitable exits. Overall, while the strategy demonstrates some profitability, its risk-return profile is weak and may require optimization in entry/exit logic, volatility filtering, or sentiment integration to compete with the benchmark performance."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XLY Analysis Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3263,
      "metadata": {},
      "outputs": [],
      "source": [
        "#url = 'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&time_from=20250101T0130&time_to=20250301T0130&limit=1000&tickers=XLY&apikey=PNM5EHRALIOT1CKJ'\n",
        "\n",
        "#response = requests.get(url)\n",
        "\n",
        "#if response.status_code == 200:\n",
        " #   sentiment_data = response.json()\n",
        "  #  sentiment_df = pd.DataFrame(sentiment_data['feed']) \n",
        "   # print(sentiment_df.head())\n",
        "#else:\n",
        " #   print(\"API call failed:\", response.status_code)\n",
        "\n",
        "#sentiment_json = response.json()\n",
        "#print(sentiment_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3264,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentiment_data = []\n",
        "for news_item in sentiment_json.get(\"feed\", []):\n",
        "    sentiment_data.append({\n",
        "            \"time_published\": pd.to_datetime(news_item[\"time_published\"]),\n",
        "            \"sentiment_score\": news_item[\"overall_sentiment_score\"],\n",
        "            \"sentiment_label\": news_item[\"overall_sentiment_label\"],\n",
        "    })\n",
        "sentiment_data = pd.DataFrame(sentiment_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3265,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentiment_data['time_published'] = sentiment_data['time_published'].dt.date\n",
        "sentiment_scores_filtered = sentiment_data[pd.to_datetime(sentiment_data['time_published']).isin(tsla.index)]\n",
        "sentiment_scores_filtered = sentiment_scores_filtered.groupby('time_published')['sentiment_score'].mean().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3266,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix the multi-level column issue by selecting the 'Volume' column and resetting its name\n",
        "xly_volume = xly[('Volume', 'XLY')].rename('Volume')\n",
        "\n",
        "# Ensure the index of tsla_volume is a column and convert it to match the type of time_published\n",
        "xly_volume = xly_volume.reset_index()\n",
        "xly_volume['Date'] = pd.to_datetime(xly_volume['Date'])\n",
        "\n",
        "# Convert time_published to datetime\n",
        "sentiment_scores_filtered['time_published'] = pd.to_datetime(sentiment_scores_filtered['time_published'])\n",
        "# Merge the dataframes\n",
        "merged_data = pd.merge(xly_volume, sentiment_scores_filtered, left_on='Date', right_on='time_published', how='inner')\n",
        "merged_data['Weighted_Sentiment'] = merged_data['Volume'] * merged_data['sentiment_score']\n",
        "merged_data['5_day_avg_sentiment'] = merged_data['Weighted_Sentiment'].rolling(window=5).mean()\n",
        "merged_data['Buy_Condition'] = merged_data['5_day_avg_sentiment'] > 0\n",
        "merged_data['5_day_avg_sentiment_norm'] = merged_data['5_day_avg_sentiment']/merged_data['Volume'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3267,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Close_XLY    ATR_10   atr_pct  position_size\n",
            "Date                                                     \n",
            "2025-02-19  225.618988  2.870099  0.012721           0.01\n",
            "2025-02-20  223.674316  2.919964  0.013055           0.01\n",
            "2025-02-21  217.790527  3.453495  0.015857           0.01\n",
            "2025-02-24  216.972778  3.270997  0.015076           0.01\n",
            "2025-02-25  215.835892  3.511334  0.016269           0.01\n",
            "2025-02-26  214.948349  3.602083  0.016758           0.01\n",
            "2025-02-27  211.846878  3.751672  0.017709           0.01\n",
            "2025-02-28  215.367203  3.836439  0.017813           0.01\n",
            "2025-03-03  211.398117  4.429805  0.020955           0.01\n",
            "2025-03-04  207.668396  4.845659  0.023334           0.01\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Flatten MultiIndex columns \n",
        "xly.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) else col\n",
        "    for col in xly.columns\n",
        "]\n",
        "\n",
        "# Calculate True Range\n",
        "xly[\"prev_close\"] = xly[\"Close_XLY\"].shift(1)\n",
        "xly[\"tr1\"] = xly[\"High_XLY\"] - xly[\"Low_XLY\"]\n",
        "xly[\"tr2\"] = abs(xly[\"High_XLY\"] - xly[\"prev_close\"])\n",
        "xly[\"tr3\"] = abs(xly[\"Low_XLY\"] - xly[\"prev_close\"])\n",
        "\n",
        "xly[\"true_range\"] = xly[[\"tr1\", \"tr2\", \"tr3\"]].max(axis=1)\n",
        "\n",
        "# 10-day ATR\n",
        "xly[\"ATR_10\"] = xly[\"true_range\"].rolling(window=10).mean()\n",
        "\n",
        "# ---- STEP 4: Calculate ATR as a percentage of closing price ----\n",
        "xly[\"atr_pct\"] = xly[\"ATR_10\"] / xly[\"Close_XLY\"]\n",
        "\n",
        "# allocating the capital\n",
        "\n",
        "def position_size(row):\n",
        "    if row[\"atr_pct\"] < 0.03:  # < 3% volatility → low risk\n",
        "        return 0.01  # allocate 1% of capital\n",
        "    else:  # ≥ 3% volatility → high risk\n",
        "        return 0.005  # allocate 0.5% of capital\n",
        "\n",
        "xly[\"position_size\"] = xly.apply(position_size, axis=1)\n",
        "\n",
        "# ---- STEP 6: Optional - Capital allocation per trade ----\n",
        "#capital = 100000 # Example: $100K total portfolio\n",
        "#xly[\"allocation_dollars\"] = xly[\"position_size\"] * capital\n",
        "\n",
        "# ---- Preview ----\n",
        "print(xly[[\"Close_XLY\", \"ATR_10\", \"atr_pct\", \"position_size\"]].tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3268,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3268,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create full-history ATR% chart\n",
        "fig_xly_atr_full = px.line(\n",
        "    xly,\n",
        "    x=xly.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"ATR% Over Time\"\n",
        ")\n",
        "\n",
        "# Add ATR threshold line\n",
        "fig_xly_atr_full.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# Show in Streamlit\n",
        "st.subheader(\"Full ATR% History for XLY\")\n",
        "st.plotly_chart(fig_xly_atr_full, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3269,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter only 2025 data\n",
        "xly_2025 = xly[xly.index.year == 2025]\n",
        "\n",
        "# Create Plotly Express figure\n",
        "fig_xly_atr_2025 = px.line(\n",
        "    xly_2025,\n",
        "    x=xly_2025.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"ATR% Over Time (2025 Only)\"\n",
        ")\n",
        "\n",
        "# Add ATR cutoff line\n",
        "fig_xly_atr_2025.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"XLY ATR% (2025 Only)\")\n",
        "st.plotly_chart(fig_xly_atr_2025, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3270,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_data = pd.merge(merged_data, xly, on='Date', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3271,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buy signals: 17\n",
            "Sell signals: 0\n",
            "Aggressive entries: 17\n",
            "Conservative entries: 0\n"
          ]
        }
      ],
      "source": [
        "# Calculate ATR percentage\n",
        "merged_data['atr_pct'] = merged_data['ATR_10'] / merged_data['Close_XLY']\n",
        "\n",
        "# Vortex crossover logic\n",
        "merged_data['VI_Cross_Up'] = (merged_data['VI+_'] > merged_data['VI-_']) & (merged_data['VI+_'].shift(1) <= merged_data['VI-_'].shift(1))\n",
        "merged_data['VI_Cross_Down'] = (merged_data['VI-_'] > merged_data['VI+_']) & (merged_data['VI-_'].shift(1) <= merged_data['VI+_'].shift(1))\n",
        "\n",
        "# Initialize signal & state columns\n",
        "merged_data['Buy_Signal'] = False\n",
        "merged_data['Sell_Signal'] = False\n",
        "merged_data['Position'] = 0\n",
        "merged_data['Entry_Type'] = None  # aggressive/conservative\n",
        "\n",
        "# Trailing stop logic variables\n",
        "in_position = False\n",
        "peak_price = 0\n",
        "\n",
        "for i in range(1, len(merged_data)):\n",
        "    row = merged_data.iloc[i]\n",
        "    idx = merged_data.index[i]\n",
        "    # Buy condition\n",
        "    if not in_position or row['VI_Cross_Up'] or row['5_day_avg_sentiment_norm']>0:\n",
        "        merged_data.at[idx, 'Buy_Signal'] = True\n",
        "        merged_data.at[idx, 'Position'] = 1\n",
        "        in_position = True\n",
        "        peak_price = row['Close_XLY']\n",
        "\n",
        "        # Entry Type: aggressive if ATR < 3%, else conservative\n",
        "        if row['atr_pct'] < 0.03:\n",
        "            merged_data.at[idx, 'Entry_Type'] = 'aggressive'\n",
        "        else:\n",
        "            merged_data.at[idx, 'Entry_Type'] = 'conservative'\n",
        "\n",
        "    # While in position, check for trailing stop or VI cross down\n",
        "    elif in_position:\n",
        "        current_price = row['Close_XLY']\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        if drawdown >= 0.03 or row['VI_Cross_Down']:\n",
        "            merged_data.at[idx, 'Sell_Signal'] = True\n",
        "            merged_data.at[idx, 'Position'] = 0\n",
        "            in_position = False\n",
        "        else:\n",
        "            merged_data.at[idx, 'Position'] = 1\n",
        "\n",
        "# Show result counts\n",
        "print(\"Buy signals:\", merged_data['Buy_Signal'].sum())\n",
        "print(\"Sell signals:\", merged_data['Sell_Signal'].sum())\n",
        "print(\"Aggressive entries:\", (merged_data['Entry_Type'] == 'aggressive').sum())\n",
        "print(\"Conservative entries:\", (merged_data['Entry_Type'] == 'conservative').sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3272,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize figure\n",
        "fig_buy_types = go.Figure()\n",
        "\n",
        "# Plot XLY price line\n",
        "fig_buy_types.add_trace(go.Scatter(\n",
        "    x=merged_data.index,\n",
        "    y=merged_data['Close_XLY'],\n",
        "    mode='lines',\n",
        "    name='XLY Price',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Aggressive Buys\n",
        "fig_buy_types.add_trace(go.Scatter(\n",
        "    x=merged_data[(merged_data['Buy_Signal']) & (merged_data['Entry_Type'] == 'aggressive')].index,\n",
        "    y=merged_data[(merged_data['Buy_Signal']) & (merged_data['Entry_Type'] == 'aggressive')]['Close_XLY'],\n",
        "    mode='markers',\n",
        "    marker=dict(symbol='triangle-up', color='limegreen', size=10),\n",
        "    name='Buy (Aggressive)'\n",
        "))\n",
        "\n",
        "# Conservative Buys\n",
        "fig_buy_types.add_trace(go.Scatter(\n",
        "    x=merged_data[(merged_data['Buy_Signal']) & (merged_data['Entry_Type'] == 'conservative')].index,\n",
        "    y=merged_data[(merged_data['Buy_Signal']) & (merged_data['Entry_Type'] == 'conservative')]['Close_XLY'],\n",
        "    mode='markers',\n",
        "    marker=dict(symbol='triangle-up', color='green', size=10),\n",
        "    name='Buy (Conservative)'\n",
        "))\n",
        "\n",
        "# Sells\n",
        "fig_buy_types.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Sell_Signal']].index,\n",
        "    y=merged_data[merged_data['Sell_Signal']]['Close_XLY'],\n",
        "    mode='markers',\n",
        "    marker=dict(symbol='triangle-down', color='red', size=10),\n",
        "    name='Sell Signal'\n",
        "))\n",
        "\n",
        "# Layout settings\n",
        "fig_buy_types.update_layout(\n",
        "    title='XLY Buy/Sell Signals Over Time',\n",
        "    xaxis_title='Date',\n",
        "    yaxis_title='Price (USD)',\n",
        "    template='plotly_white',\n",
        "    height=600\n",
        ")\n",
        "\n",
        "# Streamlit display\n",
        "st.subheader(\"XLY Buy/Sell Signal Classification\")\n",
        "st.plotly_chart(fig_buy_types, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3273,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ensure Date column is in datetime format\n",
        "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
        "\n",
        "# Initialize figure\n",
        "fig_sentiment_atr = go.Figure()\n",
        "\n",
        "# Plot 5-Day Avg Sentiment (left y-axis)\n",
        "fig_sentiment_atr.add_trace(go.Scatter(\n",
        "    x=merged_data['Date'],\n",
        "    y=merged_data['5_day_avg_sentiment_norm'],\n",
        "    mode='lines+markers',\n",
        "    name='5-Day Avg Sentiment',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Plot ATR% (right y-axis)\n",
        "fig_sentiment_atr.add_trace(go.Scatter(\n",
        "    x=merged_data['Date'],\n",
        "    y=merged_data['atr_pct'],\n",
        "    mode='lines+markers',\n",
        "    name='ATR %',\n",
        "    yaxis='y2',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Optional: Mark Buy Signals (if any)\n",
        "fig_sentiment_atr.add_trace(go.Scatter(\n",
        "    x=merged_data.loc[merged_data['Buy_Signal'], 'Date'],\n",
        "    y=merged_data.loc[merged_data['Buy_Signal'], '5_day_avg_sentiment_norm'],\n",
        "    mode='markers',\n",
        "    marker=dict(color='green', size=10, symbol='star'),\n",
        "    name='Buy Signal'\n",
        "))\n",
        "\n",
        "# Layout settings\n",
        "fig_sentiment_atr.update_layout(\n",
        "    title=\"5-Day Sentiment vs ATR% (with Buy Signals)\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis=dict(title=\"5-Day Avg Sentiment\"),\n",
        "    yaxis2=dict(title=\"ATR %\", overlaying='y', side='right'),\n",
        "    legend=dict(x=0.01, y=0.99),\n",
        "    template='plotly_white',\n",
        "    height=500\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"Sentiment vs Volatility (ATR%)\")\n",
        "st.plotly_chart(fig_sentiment_atr, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3274,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3274,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the figure\n",
        "fig_signals_xly = go.Figure()\n",
        "\n",
        "# Price line\n",
        "fig_signals_xly.add_trace(go.Scatter(\n",
        "    x=merged_data.index,\n",
        "    y=merged_data['Close_XLY'],\n",
        "    mode='lines',\n",
        "    name='XLY Price',\n",
        "    line=dict(color='royalblue')\n",
        "))\n",
        "\n",
        "# Buy signals\n",
        "fig_signals_xly.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Buy_Signal']].index,\n",
        "    y=merged_data[merged_data['Buy_Signal']]['Close_XLY'],\n",
        "    mode='markers',\n",
        "    marker=dict(symbol='triangle-up', size=10, color='green'),\n",
        "    name='Buy Signal'\n",
        "))\n",
        "\n",
        "# Sell signals\n",
        "fig_signals_xly.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Sell_Signal']].index,\n",
        "    y=merged_data[merged_data['Sell_Signal']]['Close_XLY'],\n",
        "    mode='markers',\n",
        "    marker=dict(symbol='triangle-down', size=10, color='red'),\n",
        "    name='Sell Signal'\n",
        "))\n",
        "\n",
        "# Layout settings\n",
        "fig_signals_xly.update_layout(\n",
        "    title='XLY Buy & Sell Signals',\n",
        "    template='plotly_white',\n",
        "    xaxis_title='Date',\n",
        "    yaxis_title='Price (USD)',\n",
        "    height=500\n",
        ")\n",
        "\n",
        "# Streamlit display\n",
        "st.subheader(\"XLY Buy & Sell Signals\")\n",
        "st.plotly_chart(fig_signals_xly, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Capital: $99942.65\n",
            "Total Return: $-57.35\n",
            "Total Trades: 0\n",
            "Average Profit per Trade: $nan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning:\n",
            "\n",
            "Mean of empty slice.\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in scalar divide\n",
            "\n"
          ]
        }
      ],
      "source": [
        "capital = 100000\n",
        "in_position = False\n",
        "entry_price = 0\n",
        "position_value = 0\n",
        "cash = capital\n",
        "returns = []\n",
        "\n",
        "for i in range(len(merged_data)):\n",
        "    row = merged_data.iloc[i]\n",
        "    \n",
        "    # Buy\n",
        "    if row['Buy_Signal'] and not in_position:\n",
        "        position_size = row['position_size']\n",
        "        position_value = cash * position_size\n",
        "        entry_price = row['Close_XLY']\n",
        "        shares_bought = position_value / entry_price\n",
        "        cash -= position_value\n",
        "        in_position = True\n",
        "        \n",
        "    # Sell\n",
        "    elif row['Sell_Signal'] and in_position:\n",
        "        exit_price = row['Close_XLY']\n",
        "        proceeds = shares_bought * exit_price\n",
        "        profit = proceeds - position_value\n",
        "        cash += proceeds\n",
        "        returns.append(profit)\n",
        "        in_position = False\n",
        "        position_value = 0\n",
        "        entry_price = 0\n",
        "\n",
        "# Final capital\n",
        "final_value = cash + (shares_bought * row['Close_XLY'] if in_position else 0)\n",
        "total_return = final_value - capital\n",
        "\n",
        "print(f\"Final Capital: ${final_value:.2f}\")\n",
        "print(f\"Total Return: ${total_return:.2f}\")\n",
        "print(f\"Total Trades: {len(returns)}\")\n",
        "print(f\"Average Profit per Trade: ${np.mean(returns):.2f}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Without sentiment code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3276,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Without sentiment score\n",
        "xly_copy = xly.copy()\n",
        "xly_copy['atr_pct'] = xly_copy['ATR_10'] / xly_copy['Close_XLY']\n",
        "\n",
        "# Create Buy Signal (assuming VI_Cross_Up is defined elsewhere)\n",
        "xly_copy['Buy_Signal'] = xly_copy['VI+_'] > xly_copy['VI-_']  # Vortex crossover\n",
        "# + add any other buy conditions here...\n",
        "\n",
        "# Create Sell Signal (basic)\n",
        "xly_copy['Sell_Signal'] = xly_copy['VI-_'] > xly_copy['VI+_']\n",
        "\n",
        "# Initialize position state\n",
        "xly_copy['Position'] = 0\n",
        "peak_price = 0\n",
        "\n",
        "for i in range(1, len(xly_copy)):\n",
        "    if xly_copy['Buy_Signal'].iloc[i]:\n",
        "        xly_copy.at[xly_copy.index[i], 'Position'] = 1\n",
        "        peak_price = xly_copy['Close_XLY'].iloc[i]\n",
        "    elif xly_copy['Position'].iloc[i - 1] == 1:\n",
        "        current_price = xly_copy['Close_XLY'].iloc[i]\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        if drawdown >= 0.03:\n",
        "            xly_copy.at[xly_copy.index[i], 'Sell_Signal'] = True  # trailing stop\n",
        "            xly_copy.at[xly_copy.index[i], 'Position'] = 0\n",
        "        else:\n",
        "            xly_copy.at[xly_copy.index[i], 'Position'] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3277,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Capital: $100732.95\n",
            "Total Return: $732.95\n",
            "Total Trades: 75\n",
            "Average Profit per Trade: $9.77\n"
          ]
        }
      ],
      "source": [
        "capital = 100000\n",
        "in_position = False\n",
        "entry_price = 0\n",
        "position_value = 0\n",
        "cash = capital\n",
        "returns = []\n",
        "\n",
        "for i in range(len(xly_copy)):\n",
        "    row = xly_copy.iloc[i]\n",
        "    \n",
        "    # Buy\n",
        "    if row['Buy_Signal'] and not in_position:\n",
        "        position_size = row['position_size']\n",
        "        position_value = cash * position_size\n",
        "        entry_price = row['Close_XLY']\n",
        "        shares_bought = position_value / entry_price\n",
        "        cash -= position_value\n",
        "        in_position = True\n",
        "        \n",
        "    # Sell\n",
        "    elif row['Sell_Signal'] and in_position:\n",
        "        exit_price = row['Close_XLY']\n",
        "        proceeds = shares_bought * exit_price\n",
        "        profit = proceeds - position_value\n",
        "        cash += proceeds\n",
        "        returns.append(profit)\n",
        "        in_position = False\n",
        "        position_value = 0\n",
        "        entry_price = 0\n",
        "\n",
        "# Final capital\n",
        "final_value = cash + (shares_bought * row['Close_XLY'] if in_position else 0)\n",
        "total_return = final_value - capital\n",
        "\n",
        "print(f\"Final Capital: ${final_value:.2f}\")\n",
        "print(f\"Total Return: ${total_return:.2f}\")\n",
        "print(f\"Total Trades: {len(returns)}\")\n",
        "print(f\"Average Profit per Trade: ${np.mean(returns):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3278,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-29 08:00:01.119 Serialization of dataframe to Arrow table was unsuccessful due to: (\"object of type <class 'pandas._libs.tslibs.timedeltas.Timedelta'> cannot be converted to int\", 'Conversion failed for column 0 with type object'). Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3278,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepare data\n",
        "xly = xly_copy.dropna(subset=['Close_XLY'])\n",
        "entries = xly_copy['Buy_Signal'].astype(bool)\n",
        "exits = xly_copy['Sell_Signal'].astype(bool)\n",
        "price = xly_copy['Close_XLY']\n",
        "\n",
        "# Run portfolio backtest\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    init_cash=100_000,\n",
        "    fees=0.001,\n",
        "    freq='1D'  # Fix Sharpe/Sortino/Calmar warnings\n",
        ")\n",
        "\n",
        "# Show performance stats\n",
        "st.subheader(\"XLY Portfolio Performance\")\n",
        "st.write(portfolio.stats())\n",
        "\n",
        "# Show equity chart\n",
        "fig_portfolio_xly = portfolio.plot()\n",
        "st.plotly_chart(fig_portfolio_xly, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3279,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure index is datetime and 'Close_XLY' exists\n",
        "price = merged_data['Close_XLY']\n",
        "\n",
        "# Generate entries and exits from your signals\n",
        "entries = merged_data['Buy_Signal']\n",
        "exits = merged_data['Sell_Signal']\n",
        "\n",
        "# Create portfolio\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    size=np.nan,  # Let it auto-calculate position size if fixed capital\n",
        "    init_cash=100_000,\n",
        "    fees=0.001,  # 0.1% per trade\n",
        "    slippage=0.0005  # Optional\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3280,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start                              0.00000\n",
            "End                               19.00000\n",
            "Period                            20.00000\n",
            "Start Value                   100000.00000\n",
            "End Value                     100000.00000\n",
            "Total Return [%]                   0.00000\n",
            "Benchmark Return [%]              -6.98195\n",
            "Max Gross Exposure [%]             0.00000\n",
            "Total Fees Paid                    0.00000\n",
            "Max Drawdown [%]                       NaN\n",
            "Max Drawdown Duration                  NaN\n",
            "Total Trades                       0.00000\n",
            "Total Closed Trades                0.00000\n",
            "Total Open Trades                  0.00000\n",
            "Open Trade PnL                     0.00000\n",
            "Win Rate [%]                           NaN\n",
            "Best Trade [%]                         NaN\n",
            "Worst Trade [%]                        NaN\n",
            "Avg Winning Trade [%]                  NaN\n",
            "Avg Losing Trade [%]                   NaN\n",
            "Avg Winning Trade Duration             NaN\n",
            "Avg Losing Trade Duration              NaN\n",
            "Profit Factor                          NaN\n",
            "Expectancy                             NaN\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Summary stats\n",
        "print(portfolio.stats())\n",
        "\n",
        "# Show equity curve chart in Streamlit\n",
        "st.subheader(\"XLY Equity Curve Pr\")\n",
        "fig_xly_portfolio = portfolio.plot()\n",
        "st.plotly_chart(fig_xly_portfolio, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3281,
      "metadata": {},
      "outputs": [],
      "source": [
        "xly = merged_data.dropna(subset=['Close_XLY'])\n",
        "entries = merged_data['Buy_Signal'].astype(bool)\n",
        "exits = merged_data['Sell_Signal'].astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3282,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-03-29 08:00:01.939 Serialization of dataframe to Arrow table was unsuccessful due to: (\"Could not convert Timedelta('20 days 00:00:00') with type Timedelta: tried to convert to int64\", 'Conversion failed for column 0 with type object'). Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get XLY price data\n",
        "price = merged_data['Close_XLY']\n",
        "\n",
        "# Run the portfolio\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    init_cash=100_000,\n",
        "    fees=0.001,\n",
        "    freq='1D'  # Fixes sharpe/sortino/calmars warnings\n",
        ")\n",
        "\n",
        "# Show performance stats\n",
        "st.subheader(\"XLY Portfolio Performance CV\")\n",
        "st.write(portfolio.stats())\n",
        "\n",
        "# Show chart\n",
        "fig_portfolio_xly = portfolio.plot()\n",
        "st.plotly_chart(fig_portfolio_xly, use_container_width=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SPY Analysis Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3283,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "             Close_SPY    ATR_10   atr_pct  position_size\n",
            "Date                                                     \n",
            "2025-02-19  611.091675  4.794563  0.007846           0.01\n",
            "2025-02-20  608.549377  4.806522  0.007898           0.01\n",
            "2025-02-21  598.140686  5.513399  0.009218           0.01\n",
            "2025-02-24  595.418884  5.359863  0.009002           0.01\n",
            "2025-02-25  592.457764  5.718790  0.009653           0.01\n",
            "2025-02-26  592.756836  6.146507  0.010369           0.01\n",
            "2025-02-27  583.295288  6.801538  0.011661           0.01\n",
            "2025-02-28  592.397949  7.353875  0.012414           0.01\n",
            "2025-03-03  582.019165  8.901222  0.015294           0.01\n",
            "2025-03-04  575.129883  9.901217  0.017216           0.01\n"
          ]
        }
      ],
      "source": [
        "# Flatten MultiIndex columns \n",
        "spy.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) else col\n",
        "    for col in spy.columns\n",
        "]\n",
        "\n",
        "# Calculate True Range\n",
        "spy[\"prev_close\"] = spy[\"Close_SPY\"].shift(1)\n",
        "spy[\"tr1\"] = spy[\"High_SPY\"] - spy[\"Low_SPY\"]\n",
        "spy[\"tr2\"] = abs(spy[\"High_SPY\"] - spy[\"prev_close\"])\n",
        "spy[\"tr3\"] = abs(spy[\"Low_SPY\"] - spy[\"prev_close\"])\n",
        "\n",
        "spy[\"true_range\"] = spy[[\"tr1\", \"tr2\", \"tr3\"]].max(axis=1)\n",
        "\n",
        "# 10-day ATR\n",
        "spy[\"ATR_10\"] = spy[\"true_range\"].rolling(window=10).mean()\n",
        "\n",
        "# ---- STEP 4: Calculate ATR as a percentage of closing price ----\n",
        "spy[\"atr_pct\"] = spy[\"ATR_10\"] / spy[\"Close_SPY\"]\n",
        "\n",
        "# allocating the capital\n",
        "\n",
        "def position_size(row):\n",
        "    if row[\"atr_pct\"] < 0.03:  # < 3% volatility → low risk\n",
        "        return 0.01  # allocate 1% of capital\n",
        "    else:  # ≥ 3% volatility → high risk\n",
        "        return 0.005  # allocate 0.5% of capital\n",
        "\n",
        "spy[\"position_size\"] = spy.apply(position_size, axis=1)\n",
        "\n",
        "# ---- STEP 6: Optional - Capital allocation per trade ----\n",
        "#capital = 100000 # Example: $100K total portfolio\n",
        "#spy[\"allocation_dollars\"] = spy[\"position_size\"] * capital\n",
        "\n",
        "# ---- Preview ----\n",
        "print(spy[[\"Close_SPY\", \"ATR_10\", \"atr_pct\", \"position_size\"]].tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3284,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3284,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the ATR% chart for SPY (full period)\n",
        "fig_atr_spy_full = px.line(\n",
        "    spy,\n",
        "    x=spy.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"SPY ATR% Over Time\"\n",
        ")\n",
        "\n",
        "# Add horizontal threshold\n",
        "fig_atr_spy_full.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"SPY ATR% Over Time\")\n",
        "st.plotly_chart(fig_atr_spy_full, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3285,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter SPY data for 2025 only\n",
        "spy_2025 = spy[spy.index.year == 2025]\n",
        "\n",
        "# Create ATR% chart\n",
        "fig_atr_spy_2025 = px.line(\n",
        "    spy_2025,\n",
        "    x=spy_2025.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"SPY ATR% Over Time (2025 Only)\"\n",
        ")\n",
        "\n",
        "# Add horizontal cutoff line\n",
        "fig_atr_spy_2025.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"SPY ATR% - 2025 Only\")\n",
        "st.plotly_chart(fig_atr_spy_2025, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3286,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Without sentiment score\n",
        "spy_copy = spy.copy()\n",
        "spy_copy['atr_pct'] = spy_copy['ATR_10'] / spy_copy['Close_SPY']\n",
        "\n",
        "# Create Buy Signal (assuming VI_Cross_Up is defined elsewhere)\n",
        "spy_copy['Buy_Signal'] = spy_copy['VI+_'] > spy_copy['VI-_']  # Vortex crossover\n",
        "\n",
        "# Create Sell Signal (basic)\n",
        "spy_copy['Sell_Signal'] = spy_copy['VI-_'] > spy_copy['VI+_']\n",
        "\n",
        "# Initialize position state\n",
        "spy_copy['Position'] = 0\n",
        "peak_price = 0\n",
        "\n",
        "for i in range(1, len(spy_copy)):\n",
        "    if spy_copy['Buy_Signal'].iloc[i]:\n",
        "        spy_copy.at[spy_copy.index[i], 'Position'] = 1\n",
        "        peak_price = spy_copy['Close_SPY'].iloc[i]\n",
        "    elif spy_copy['Position'].iloc[i - 1] == 1:\n",
        "        current_price = spy_copy['Close_SPY'].iloc[i]\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        if drawdown >= 0.03:\n",
        "            spy_copy.at[spy_copy.index[i], 'Sell_Signal'] = True  # trailing stop\n",
        "            spy_copy.at[spy_copy.index[i], 'Position'] = 0\n",
        "        else:\n",
        "            spy_copy.at[spy_copy.index[i], 'Position'] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3287,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Capital: $100515.03\n",
            "Total Return: $515.03\n",
            "Total Trades: 56\n",
            "Average Profit per Trade: $9.20\n"
          ]
        }
      ],
      "source": [
        "capital = 100000\n",
        "in_position = False\n",
        "entry_price = 0\n",
        "position_value = 0\n",
        "cash = capital\n",
        "returns = []\n",
        "\n",
        "for i in range(len(spy_copy)):\n",
        "    row = spy_copy.iloc[i]\n",
        "    \n",
        "    # Buy\n",
        "    if row['Buy_Signal'] and not in_position:\n",
        "        position_size = row['position_size']\n",
        "        position_value = cash * position_size\n",
        "        entry_price = row['Close_SPY']\n",
        "        shares_bought = position_value / entry_price\n",
        "        cash -= position_value\n",
        "        in_position = True\n",
        "        \n",
        "    # Sell\n",
        "    elif row['Sell_Signal'] and in_position:\n",
        "        exit_price = row['Close_SPY']\n",
        "        proceeds = shares_bought * exit_price\n",
        "        profit = proceeds - position_value\n",
        "        cash += proceeds\n",
        "        returns.append(profit)\n",
        "        in_position = False\n",
        "        position_value = 0\n",
        "        entry_price = 0\n",
        "\n",
        "# Final capital\n",
        "final_value = cash + (shares_bought * row['Close_SPY'] if in_position else 0)\n",
        "total_return = final_value - capital\n",
        "\n",
        "print(f\"Final Capital: ${final_value:.2f}\")\n",
        "print(f\"Total Return: ${total_return:.2f}\")\n",
        "print(f\"Total Trades: {len(returns)}\")\n",
        "print(f\"Average Profit per Trade: ${np.mean(returns):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3288,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start                         2019-01-02 00:00:00\n",
            "End                           2025-03-04 00:00:00\n",
            "Period                                       1551\n",
            "Start Value                              100000.0\n",
            "End Value                           149876.276862\n",
            "Total Return [%]                        49.876277\n",
            "Benchmark Return [%]                   153.411688\n",
            "Max Gross Exposure [%]                      100.0\n",
            "Total Fees Paid                      14500.399389\n",
            "Max Drawdown [%]                        19.809422\n",
            "Max Drawdown Duration                       584.0\n",
            "Total Trades                                   56\n",
            "Total Closed Trades                            56\n",
            "Total Open Trades                               0\n",
            "Open Trade PnL                                0.0\n",
            "Win Rate [%]                            55.357143\n",
            "Best Trade [%]                           7.385103\n",
            "Worst Trade [%]                         -9.885439\n",
            "Avg Winning Trade [%]                    3.135412\n",
            "Avg Losing Trade [%]                    -2.130086\n",
            "Avg Winning Trade Duration              28.258065\n",
            "Avg Losing Trade Duration                    7.56\n",
            "Profit Factor                              1.7122\n",
            "Expectancy                             890.647801\n",
            "dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spy = spy_copy.dropna(subset=['Close_SPY'])\n",
        "entries = spy_copy['Buy_Signal'].astype(bool)\n",
        "exits = spy_copy['Sell_Signal'].astype(bool)\n",
        "\n",
        "price = spy_copy['Close_SPY']\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    init_cash=100_000,\n",
        "    fees=0.001\n",
        ")\n",
        "\n",
        "print(portfolio.stats())\n",
        "\n",
        "# Display chart\n",
        "fig_portfolio_spy = portfolio.plot()\n",
        "st.plotly_chart(fig_portfolio_spy, use_container_width=True)\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3289,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "tsla = yf.download('TSLA', start='2019-01-01', end='2025-03-05')\n",
        "xly = yf.download('XLY', start='2019-01-01', end='2025-03-05')\n",
        "spy = yf.download('SPY', start='2019-01-01', end='2025-03-05')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3290,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_vortex(df, value, n):\n",
        "    \"\"\"Calculate Vortex Indicator VI+ and VI-.\"\"\"\n",
        "    high = df[(\"High_\"+value)]\n",
        "    low = df[(\"Low_\"+value)]\n",
        "    close = df[(\"Close_\"+value)]\n",
        "\n",
        "    vm_plus = abs(high - low.shift(1))   # |Today's High - Yesterday's Low|\n",
        "    vm_minus = abs(low - high.shift(1))  # |Today's Low - Yesterday's High|\n",
        "\n",
        "    tr = pd.concat([\n",
        "        high - low,\n",
        "        abs(high - close.shift(1)),\n",
        "        abs(low - close.shift(1))\n",
        "    ], axis=1).max(axis=1)\n",
        "\n",
        "    sum_vm_plus = vm_plus.rolling(window=n).sum()\n",
        "    sum_vm_minus = vm_minus.rolling(window=n).sum()\n",
        "    sum_tr = tr.rolling(window=n).sum()\n",
        "\n",
        "    vi_plus = sum_vm_plus / sum_tr\n",
        "    vi_minus = sum_vm_minus / sum_tr\n",
        "\n",
        "    return vi_plus, vi_minus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3291,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsla.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) else col\n",
        "    for col in tsla.columns\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3292,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n",
            "2025-03-29 08:00:03.539 Serialization of dataframe to Arrow table was unsuccessful due to: ('Expected np.datetime64 but got: double', 'Conversion failed for column 0 with type object'). Applying automatic fixes for column types to make the dataframe Arrow-compatible.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Best Performing Period: 7 days\n",
            "Start                         2019-01-02 00:00:00\n",
            "End                           2025-03-04 00:00:00\n",
            "Period                                       1551\n",
            "Start Value                               10000.0\n",
            "End Value                            10480.194603\n",
            "Total Return [%]                         4.801946\n",
            "Benchmark Return [%]                  1215.813231\n",
            "Max Gross Exposure [%]                   4.554966\n",
            "Total Fees Paid                               0.0\n",
            "Max Drawdown [%]                         0.793073\n",
            "Max Drawdown Duration                       351.0\n",
            "Total Trades                                  113\n",
            "Total Closed Trades                           113\n",
            "Total Open Trades                               0\n",
            "Open Trade PnL                                0.0\n",
            "Win Rate [%]                            44.247788\n",
            "Best Trade [%]                         128.434899\n",
            "Worst Trade [%]                        -15.721837\n",
            "Avg Winning Trade [%]                   14.052436\n",
            "Avg Losing Trade [%]                    -4.125181\n",
            "Avg Winning Trade Duration                  11.44\n",
            "Avg Losing Trade Duration                4.206349\n",
            "Profit Factor                            2.096188\n",
            "Expectancy                                4.24951\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Define a list of different smoothing periods to test for the Vortex Indicator\n",
        "periods = [7, 14, 21, 30]\n",
        "results = {}  # Dictionary to store performance metrics for each period\n",
        "\n",
        "# Loop through each smoothing period\n",
        "for n in periods:\n",
        "    # === Compute Vortex Indicator for the given period ===\n",
        "    tsla[f'VI+_{n}'], tsla[f'VI-_{n}'] = calculate_vortex(tsla, 'TSLA', n)\n",
        "\n",
        "    # === Generate Buy/Sell signals based on crossover logic ===\n",
        "    # Buy when VI+ crosses above VI-\n",
        "    tsla[f'Buy_{n}'] = tsla[f'VI+_{n}'] > tsla[f'VI-_{n}']\n",
        "    # Sell when VI- crosses above VI+\n",
        "    tsla[f'Sell_{n}'] = tsla[f'VI-_{n}'] > tsla[f'VI+_{n}']\n",
        "\n",
        "    # === Convert boolean signals to actual entry/exit Series ===\n",
        "    entries = tsla[f'Buy_{n}']\n",
        "    exits = tsla[f'Sell_{n}']\n",
        "\n",
        "    # === Run a backtest using vectorbt Portfolio object ===\n",
        "    portfolio = vbt.Portfolio.from_signals(\n",
        "        close=tsla['Close_TSLA'],  # TSLA closing prices\n",
        "        entries=entries,\n",
        "        exits=exits,\n",
        "        size=1,  # Assume buying 1 share per trade\n",
        "        init_cash=10_000  # Initial capital for backtest\n",
        "    )\n",
        "\n",
        "    # === Store backtest performance metrics in results dict ===\n",
        "    stats = portfolio.stats()\n",
        "    results[n] = stats\n",
        "\n",
        "# Identify the period with the highest total return\n",
        "best_period = max(results, key=lambda x: results[x]['Total Return [%]'])\n",
        "print(f\"✅ Best Performing Period: {best_period} days\")\n",
        "\n",
        "# Rebuild portfolio using the best period to visualize it\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=tsla['Close_TSLA'],\n",
        "    entries=tsla[f'VI+_{best_period}'] > tsla[f'VI-_{best_period}'],\n",
        "    exits=tsla[f'VI-_{best_period}'] > tsla[f'VI+_{best_period}'],\n",
        "    size=1,\n",
        "    init_cash=10_000\n",
        ")\n",
        "\n",
        "# Plot the results of the best strategy\n",
        "# Generate plot figure\n",
        "fig_vortex_best = portfolio.plot()\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(f\"Best Performing Strategy: {best_period}-Day Smoothing\")\n",
        "st.plotly_chart(fig_vortex_best, use_container_width=True)\n",
        "\n",
        "# Show stats\n",
        "st.subheader(\"Performance Stats\")\n",
        "st.write(portfolio.stats())\n",
        "\n",
        "print(portfolio.stats())\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Peer Comparison: Apple Analysis Results "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3293,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "appl = yf.download('AAPL', start='2019-01-01', end='2025-03-05')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3294,
      "metadata": {},
      "outputs": [],
      "source": [
        "appl.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) else col\n",
        "    for col in appl.columns\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3295,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_vortex(df, value, n):\n",
        "    \"\"\"Calculate Vortex Indicator VI+ and VI-.\"\"\"\n",
        "    high = df[(\"High_\"+value)]\n",
        "    low = df[(\"Low_\"+value)]\n",
        "    close = df[(\"Close_\"+value)]\n",
        "\n",
        "    vm_plus = abs(high - low.shift(1))   # |Today's High - Yesterday's Low|\n",
        "    vm_minus = abs(low - high.shift(1))  # |Today's Low - Yesterday's High|\n",
        "\n",
        "    tr = pd.concat([\n",
        "        high - low,\n",
        "        abs(high - close.shift(1)),\n",
        "        abs(low - close.shift(1))\n",
        "    ], axis=1).max(axis=1)\n",
        "\n",
        "    sum_vm_plus = vm_plus.rolling(window=n).sum()\n",
        "    sum_vm_minus = vm_minus.rolling(window=n).sum()\n",
        "    sum_tr = tr.rolling(window=n).sum()\n",
        "\n",
        "    vi_plus = sum_vm_plus / sum_tr\n",
        "    vi_minus = sum_vm_minus / sum_tr\n",
        "\n",
        "    return vi_plus, vi_minus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3296,
      "metadata": {},
      "outputs": [],
      "source": [
        "appl['VI+_'], appl['VI-_'] = calculate_vortex(appl, 'AAPL', 14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3297,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                     sentiment_score   sentiment_label\n",
            "time_published                                        \n",
            "2025-03-01 00:00:18         0.225994  Somewhat-Bullish\n",
            "2025-02-28 22:06:00         0.291136  Somewhat-Bullish\n",
            "2025-02-28 17:55:55         0.082801           Neutral\n",
            "2025-02-28 17:00:45         0.374552           Bullish\n",
            "2025-02-28 15:00:46         0.287114  Somewhat-Bullish\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 669 entries, 2025-03-01 00:00:18 to 2025-01-15 14:45:51\n",
            "Data columns (total 2 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   sentiment_score  669 non-null    float64\n",
            " 1   sentiment_label  669 non-null    object \n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 15.7+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Load from file\n",
        "with open(\"AAPL_sentiment_raw.json\", \"r\") as f:\n",
        "    sentiment_json = json.load(f)\n",
        "\n",
        "# Extract feed\n",
        "sentiment_feed = sentiment_json.get(\"feed\", [])\n",
        "\n",
        "# Extract useful fields\n",
        "sentiment_data = []\n",
        "\n",
        "for item in sentiment_feed:\n",
        "    try:\n",
        "        sentiment_data.append({\n",
        "            \"time_published\": pd.to_datetime(item[\"time_published\"]),\n",
        "            \"sentiment_score\": float(item[\"overall_sentiment_score\"]),\n",
        "            \"sentiment_label\": item[\"overall_sentiment_label\"],\n",
        "        })\n",
        "    except (KeyError, ValueError, TypeError):\n",
        "        continue  # Skip malformed rows\n",
        "\n",
        "# Convert to DataFrame\n",
        "sentiment_df = pd.DataFrame(sentiment_data)\n",
        "sentiment_df.set_index(\"time_published\", inplace=True)\n",
        "\n",
        "# View result\n",
        "print(sentiment_df.head())\n",
        "print(sentiment_df.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3298,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentiment_data = []\n",
        "for news_item in sentiment_json.get(\"feed\", []):\n",
        "    sentiment_data.append({\n",
        "            \"time_published\": pd.to_datetime(news_item[\"time_published\"]),\n",
        "            \"sentiment_score\": news_item[\"overall_sentiment_score\"],\n",
        "            \"sentiment_label\": news_item[\"overall_sentiment_label\"],\n",
        "    })\n",
        "sentiment_data = pd.DataFrame(sentiment_data)\n",
        "sentiment_data['time_published'] = sentiment_data['time_published'].dt.date\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3299,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "31\n"
          ]
        }
      ],
      "source": [
        "sentiment_scores_filtered = sentiment_data[pd.to_datetime(sentiment_data['time_published']).isin(appl.index)]\n",
        "sentiment_scores_filtered = sentiment_scores_filtered.groupby('time_published')['sentiment_score'].mean().reset_index()\n",
        "print(len(sentiment_scores_filtered))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3300,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Volume_AAPL</th>\n",
              "      <th>time_published</th>\n",
              "      <th>sentiment_score</th>\n",
              "      <th>Weighted_Sentiment</th>\n",
              "      <th>5_day_avg_sentiment</th>\n",
              "      <th>Buy_Condition</th>\n",
              "      <th>5_day_avg_sentiment_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2025-01-15</td>\n",
              "      <td>39832000</td>\n",
              "      <td>2025-01-15</td>\n",
              "      <td>0.223177</td>\n",
              "      <td>8.889575e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2025-01-16</td>\n",
              "      <td>71759100</td>\n",
              "      <td>2025-01-16</td>\n",
              "      <td>0.237567</td>\n",
              "      <td>1.704756e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2025-01-17</td>\n",
              "      <td>68488300</td>\n",
              "      <td>2025-01-17</td>\n",
              "      <td>0.130304</td>\n",
              "      <td>8.924326e+06</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2025-01-21</td>\n",
              "      <td>98070400</td>\n",
              "      <td>2025-01-21</td>\n",
              "      <td>0.169273</td>\n",
              "      <td>1.660064e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2025-01-22</td>\n",
              "      <td>64126500</td>\n",
              "      <td>2025-01-22</td>\n",
              "      <td>0.182421</td>\n",
              "      <td>1.169803e+07</td>\n",
              "      <td>1.263203e+07</td>\n",
              "      <td>True</td>\n",
              "      <td>0.231401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date  Volume_AAPL time_published  sentiment_score  Weighted_Sentiment  \\\n",
              "0 2025-01-15     39832000     2025-01-15         0.223177        8.889575e+06   \n",
              "1 2025-01-16     71759100     2025-01-16         0.237567        1.704756e+07   \n",
              "2 2025-01-17     68488300     2025-01-17         0.130304        8.924326e+06   \n",
              "3 2025-01-21     98070400     2025-01-21         0.169273        1.660064e+07   \n",
              "4 2025-01-22     64126500     2025-01-22         0.182421        1.169803e+07   \n",
              "\n",
              "   5_day_avg_sentiment  Buy_Condition  5_day_avg_sentiment_norm  \n",
              "0                  NaN          False                       NaN  \n",
              "1                  NaN          False                       NaN  \n",
              "2                  NaN          False                       NaN  \n",
              "3                  NaN          False                       NaN  \n",
              "4         1.263203e+07           True                  0.231401  "
            ]
          },
          "execution_count": 3300,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "appl_volume = appl[('Volume_AAPL')].reset_index()\n",
        "appl_volume['Date'] = pd.to_datetime(appl_volume['Date'])\n",
        "\n",
        "sentiment_scores_filtered['time_published'] = pd.to_datetime(sentiment_scores_filtered['time_published'])\n",
        "\n",
        "merged_data = pd.merge(appl_volume, sentiment_scores_filtered, left_on='Date', right_on='time_published', how='inner')\n",
        "merged_data['Weighted_Sentiment'] = merged_data['Volume_AAPL'] * merged_data['sentiment_score']\n",
        "merged_data['5_day_avg_sentiment'] = merged_data['Weighted_Sentiment'].rolling(window=5).mean()\n",
        "merged_data['Buy_Condition'] = merged_data['5_day_avg_sentiment'] > 0\n",
        "merged_data['5_day_avg_sentiment_norm'] = merged_data['5_day_avg_sentiment']/merged_data['Volume_AAPL'].mean()\n",
        "\n",
        "merged_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3301,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Close_AAPL    ATR_10   atr_pct  position_size\n",
            "Date                                                     \n",
            "2025-02-19  244.869995  4.939392  0.020171           0.01\n",
            "2025-02-20  245.830002  4.735891  0.019265           0.01\n",
            "2025-02-21  245.550003  4.746260  0.019329           0.01\n",
            "2025-02-24  247.100006  4.517000  0.018280           0.01\n",
            "2025-02-25  247.039993  4.687000  0.018973           0.01\n",
            "2025-02-26  240.360001  4.719998  0.019637           0.01\n",
            "2025-02-27  237.300003  4.631998  0.019520           0.01\n",
            "2025-02-28  241.839996  5.143999  0.021270           0.01\n",
            "2025-03-03  238.029999  5.479999  0.023022           0.01\n",
            "2025-03-04  235.929993  5.685001  0.024096           0.01\n"
          ]
        }
      ],
      "source": [
        "# Calculate True Range\n",
        "appl[\"prev_close\"] = appl[\"Close_AAPL\"].shift(1)\n",
        "appl[\"tr1\"] = appl[\"High_AAPL\"] - appl[\"Low_AAPL\"]\n",
        "appl[\"tr2\"] = abs(appl[\"High_AAPL\"] - appl[\"prev_close\"])\n",
        "appl[\"tr3\"] = abs(appl[\"Low_AAPL\"] - appl[\"prev_close\"])\n",
        "\n",
        "appl[\"true_range\"] = appl[[\"tr1\", \"tr2\", \"tr3\"]].max(axis=1)\n",
        "\n",
        "# 10-day ATR\n",
        "appl[\"ATR_10\"] = appl[\"true_range\"].rolling(window=10).mean()\n",
        "\n",
        "# ---- STEP 4: Calculate ATR as a percentage of closing price ----\n",
        "appl[\"atr_pct\"] = appl[\"ATR_10\"] / appl[\"Close_AAPL\"]\n",
        "\n",
        "# allocating the capital\n",
        "\n",
        "def position_size(row):\n",
        "    if row[\"atr_pct\"] < 0.03:  # < 3% volatility → low risk\n",
        "        return 0.01  # allocate 1% of capital\n",
        "    else:  # ≥ 3% volatility → high risk\n",
        "        return 0.005  # allocate 0.5% of capital\n",
        "\n",
        "appl[\"position_size\"] = appl.apply(position_size, axis=1)\n",
        "\n",
        "print(appl[[\"Close_AAPL\", \"ATR_10\", \"atr_pct\", \"position_size\"]].tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3302,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3302,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create ATR% line chart\n",
        "fig_atr_aapl_full = px.line(\n",
        "    appl,\n",
        "    x=appl.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"AAPL ATR% Over Time\"\n",
        ")\n",
        "\n",
        "# Add horizontal cutoff line\n",
        "fig_atr_aapl_full.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"AAPL ATR% Over Time\")\n",
        "st.plotly_chart(fig_atr_aapl_full, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3303,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3303,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter only 2025 data\n",
        "appl_2025 = appl[appl.index.year == 2025]\n",
        "\n",
        "# Create the chart\n",
        "fig_atr_aapl_2025 = px.line(\n",
        "    appl_2025,\n",
        "    x=appl_2025.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"AAPL ATR% Over Time (2025 Only)\"\n",
        ")\n",
        "\n",
        "# Add volatility threshold line\n",
        "fig_atr_aapl_2025.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"AAPL ATR% - 2025 Only\")\n",
        "st.plotly_chart(fig_atr_aapl_2025, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3304,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_data = pd.merge(merged_data, appl, on='Date', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3305,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buy signals: 28\n",
            "Sell signals: 1\n",
            "Aggressive entries: 23\n",
            "Conservative entries: 5\n"
          ]
        }
      ],
      "source": [
        "# Calculate ATR percentage\n",
        "merged_data['atr_pct'] = merged_data['ATR_10'] / merged_data['Close_AAPL']\n",
        "\n",
        "# Vortex crossover logic\n",
        "merged_data['VI_Cross_Up'] = (merged_data['VI+_'] > merged_data['VI-_']) & (merged_data['VI+_'].shift(1) <= merged_data['VI-_'].shift(1))\n",
        "merged_data['VI_Cross_Down'] = (merged_data['VI-_'] > merged_data['VI+_']) & (merged_data['VI-_'].shift(1) <= merged_data['VI+_'].shift(1))\n",
        "\n",
        "# Initialize signal & state columns\n",
        "merged_data['Buy_Signal'] = False\n",
        "merged_data['Sell_Signal'] = False\n",
        "merged_data['Position'] = 0\n",
        "merged_data['Entry_Type'] = None  # aggressive/conservative\n",
        "\n",
        "# Trailing stop logic variables\n",
        "in_position = False\n",
        "peak_price = 0\n",
        "\n",
        "for i in range(1, len(merged_data)):\n",
        "    row = merged_data.iloc[i]\n",
        "    idx = merged_data.index[i]\n",
        "    # Buy condition\n",
        "    if not in_position or row['VI_Cross_Up'] or row['5_day_avg_sentiment_norm']>0:\n",
        "        merged_data.at[idx, 'Buy_Signal'] = True\n",
        "        merged_data.at[idx, 'Position'] = 1\n",
        "        in_position = True\n",
        "        peak_price = row['Close_AAPL']\n",
        "\n",
        "        # Entry Type: aggressive if ATR < 3%, else conservative\n",
        "        if row['atr_pct'] < 0.03:\n",
        "            merged_data.at[idx, 'Entry_Type'] = 'aggressive'\n",
        "        else:\n",
        "            merged_data.at[idx, 'Entry_Type'] = 'conservative'\n",
        "\n",
        "    # While in position, check for trailing stop or VI cross down\n",
        "    elif in_position:\n",
        "        current_price = row['Close_AAPL']\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        if drawdown >= 0.03 or row['VI_Cross_Down']:\n",
        "            merged_data.at[idx, 'Sell_Signal'] = True\n",
        "            merged_data.at[idx, 'Position'] = 0\n",
        "            in_position = False\n",
        "        else:\n",
        "            merged_data.at[idx, 'Position'] = 1\n",
        "\n",
        "# Show result counts\n",
        "print(\"Buy signals:\", merged_data['Buy_Signal'].sum())\n",
        "print(\"Sell signals:\", merged_data['Sell_Signal'].sum())\n",
        "print(\"Aggressive entries:\", (merged_data['Entry_Type'] == 'aggressive').sum())\n",
        "print(\"Conservative entries:\", (merged_data['Entry_Type'] == 'conservative').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3306,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3306,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the figure\n",
        "fig_entry_signals = go.Figure()\n",
        "\n",
        "# Closing price\n",
        "fig_entry_signals.add_trace(go.Scatter(\n",
        "    x=merged_data.index,\n",
        "    y=merged_data['Close_AAPL'],\n",
        "    mode='lines',\n",
        "    name='merged_data Price',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Aggressive buys\n",
        "fig_entry_signals.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Buy_Signal'] & (merged_data['Entry_Type'] == 'aggressive')].index,\n",
        "    y=merged_data[merged_data['Buy_Signal'] & (merged_data['Entry_Type'] == 'aggressive')]['Close_AAPL'],\n",
        "    mode='markers',\n",
        "    name='Buy (Aggressive)',\n",
        "    marker=dict(symbol='triangle-up', color='limegreen', size=10)\n",
        "))\n",
        "\n",
        "# Conservative buys\n",
        "fig_entry_signals.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Buy_Signal'] & (merged_data['Entry_Type'] == 'conservative')].index,\n",
        "    y=merged_data[merged_data['Buy_Signal'] & (merged_data['Entry_Type'] == 'conservative')]['Close_AAPL'],\n",
        "    mode='markers',\n",
        "    name='Buy (Conservative)',\n",
        "    marker=dict(symbol='triangle-up', color='green', size=10)\n",
        "))\n",
        "\n",
        "# Sell signals\n",
        "fig_entry_signals.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Sell_Signal']].index,\n",
        "    y=merged_data[merged_data['Sell_Signal']]['Close_AAPL'],\n",
        "    mode='markers',\n",
        "    name='Sell Signal',\n",
        "    marker=dict(symbol='triangle-down', color='red', size=10)\n",
        "))\n",
        "\n",
        "# Layout\n",
        "fig_entry_signals.update_layout(\n",
        "    title='merged_data Buy/Sell Signals Over Time',\n",
        "    xaxis_title='Date',\n",
        "    yaxis_title='Price (USD)',\n",
        "    template='plotly_white',\n",
        "    height=600\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"AAPL Buy & Sell Signals (Aggressive vs Conservative)\")\n",
        "st.plotly_chart(fig_entry_signals, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3307,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3307,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ensure datetime format\n",
        "merged_data['Date'] = pd.to_datetime(merged_data['Date'])\n",
        "\n",
        "# Create figure\n",
        "fig_sentiment_atr = go.Figure()\n",
        "\n",
        "# 5-Day Avg Sentiment\n",
        "fig_sentiment_atr.add_trace(go.Scatter(\n",
        "    x=merged_data['Date'],\n",
        "    y=merged_data['5_day_avg_sentiment_norm'],\n",
        "    mode='lines+markers',\n",
        "    name='5-Day Avg Sentiment',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# ATR %\n",
        "fig_sentiment_atr.add_trace(go.Scatter(\n",
        "    x=merged_data['Date'],\n",
        "    y=merged_data['atr_pct'],\n",
        "    mode='lines+markers',\n",
        "    name='ATR %',\n",
        "    yaxis='y2',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Optional: Buy Signal Markers\n",
        "fig_sentiment_atr.add_trace(go.Scatter(\n",
        "    x=merged_data.loc[merged_data['Buy_Signal'], 'Date'],\n",
        "    y=merged_data.loc[merged_data['Buy_Signal'], '5_day_avg_sentiment_norm'],\n",
        "    mode='markers',\n",
        "    name='Buy Signal',\n",
        "    marker=dict(color='green', size=10, symbol='star')\n",
        "))\n",
        "\n",
        "# Dual Y-axis layout\n",
        "fig_sentiment_atr.update_layout(\n",
        "    title=\"5-Day Sentiment vs ATR % (with Buy Signals)\",\n",
        "    xaxis_title='Date',\n",
        "    yaxis=dict(title='5-Day Avg Sentiment'),\n",
        "    yaxis2=dict(title='ATR %', overlaying='y', side='right'),\n",
        "    legend=dict(x=0.01, y=0.99),\n",
        "    height=500\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"5-Day Avg Sentiment vs ATR% (with Buy Signals)\")\n",
        "st.plotly_chart(fig_sentiment_atr, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3308,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3308,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create uniquely named figure\n",
        "fig_aapl_signals = go.Figure()\n",
        "\n",
        "# Plot AAPL closing price\n",
        "fig_aapl_signals.add_trace(go.Scatter(\n",
        "    x=merged_data.index,\n",
        "    y=merged_data['Close_AAPL'],\n",
        "    mode='lines',\n",
        "    name='AAPL Price'\n",
        "))\n",
        "\n",
        "# Buy markers\n",
        "fig_aapl_signals.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Buy_Signal']].index,\n",
        "    y=merged_data[merged_data['Buy_Signal']]['Close_AAPL'],\n",
        "    mode='markers',\n",
        "    marker=dict(symbol='triangle-up', size=10, color='green'),\n",
        "    name='Buy Signal'\n",
        "))\n",
        "\n",
        "# Sell markers\n",
        "fig_aapl_signals.add_trace(go.Scatter(\n",
        "    x=merged_data[merged_data['Sell_Signal']].index,\n",
        "    y=merged_data[merged_data['Sell_Signal']]['Close_AAPL'],\n",
        "    mode='markers',\n",
        "    marker=dict(symbol='triangle-down', size=10, color='red'),\n",
        "    name='Sell Signal'\n",
        "))\n",
        "\n",
        "# Update layout\n",
        "fig_aapl_signals.update_layout(\n",
        "    title='AAPL Buy & Sell Signals',\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "# Streamlit output\n",
        "st.plotly_chart(fig_aapl_signals, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3309,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Capital: $100057.01\n",
            "Total Return: $57.01\n",
            "Total Trades: 1\n",
            "Average Profit per Trade: $-24.62\n"
          ]
        }
      ],
      "source": [
        "capital = 100000\n",
        "in_position = False\n",
        "entry_price = 0\n",
        "position_value = 0\n",
        "cash = capital\n",
        "returns = []\n",
        "\n",
        "for i in range(len(merged_data)):\n",
        "    row = merged_data.iloc[i]\n",
        "    \n",
        "    # Buy\n",
        "    if row['Buy_Signal'] and not in_position:\n",
        "        position_size = row['position_size']\n",
        "        position_value = cash * position_size\n",
        "        entry_price = row['Close_AAPL']\n",
        "        shares_bought = position_value / entry_price\n",
        "        cash -= position_value\n",
        "        in_position = True\n",
        "        \n",
        "    # Sell\n",
        "    elif row['Sell_Signal'] and in_position:\n",
        "        exit_price = row['Close_AAPL']\n",
        "        proceeds = shares_bought * exit_price\n",
        "        profit = proceeds - position_value\n",
        "        cash += proceeds\n",
        "        returns.append(profit)\n",
        "        in_position = False\n",
        "        position_value = 0\n",
        "        entry_price = 0\n",
        "\n",
        "# Final capital\n",
        "final_value = cash + (shares_bought * row['Close_AAPL'] if in_position else 0)\n",
        "total_return = final_value - capital\n",
        "\n",
        "print(f\"Final Capital: ${final_value:.2f}\")\n",
        "print(f\"Total Return: ${total_return:.2f}\")\n",
        "print(f\"Total Trades: {len(returns)}\")\n",
        "print(f\"Average Profit per Trade: ${np.mean(returns):.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3310,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start                              0.000000\n",
            "End                               30.000000\n",
            "Period                            31.000000\n",
            "Start Value                   100000.000000\n",
            "End Value                     100000.000000\n",
            "Total Return [%]                   0.000000\n",
            "Benchmark Return [%]               1.780762\n",
            "Max Gross Exposure [%]             0.000000\n",
            "Total Fees Paid                    0.000000\n",
            "Max Drawdown [%]                        NaN\n",
            "Max Drawdown Duration                   NaN\n",
            "Total Trades                       0.000000\n",
            "Total Closed Trades                0.000000\n",
            "Total Open Trades                  0.000000\n",
            "Open Trade PnL                     0.000000\n",
            "Win Rate [%]                            NaN\n",
            "Best Trade [%]                          NaN\n",
            "Worst Trade [%]                         NaN\n",
            "Avg Winning Trade [%]                   NaN\n",
            "Avg Losing Trade [%]                    NaN\n",
            "Avg Winning Trade Duration              NaN\n",
            "Avg Losing Trade Duration               NaN\n",
            "Profit Factor                           NaN\n",
            "Expectancy                              NaN\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import vectorbt as vbt\n",
        "\n",
        "# Make sure index is datetime and 'Close_TSLA' exists\n",
        "price = merged_data['Close_AAPL']\n",
        "\n",
        "# Generate entries and exits from your signals\n",
        "entries = merged_data['Buy_Signal']\n",
        "exits = merged_data['Sell_Signal']\n",
        "\n",
        "# Create portfolio\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    size=np.nan,  # Let it auto-calculate position size if fixed capital\n",
        "    init_cash=100_000,\n",
        "    fees=0.001,  # 0.1% per trade\n",
        "    slippage=0.0005  # Optional\n",
        ")\n",
        "\n",
        "# Plot portfolio value\n",
        "print(portfolio.stats())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3311,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start                              0.000000\n",
            "End                               30.000000\n",
            "Period                            31.000000\n",
            "Start Value                   100000.000000\n",
            "End Value                     105185.963339\n",
            "Total Return [%]                   5.185963\n",
            "Benchmark Return [%]               1.780762\n",
            "Max Gross Exposure [%]           100.000000\n",
            "Total Fees Paid                  294.586321\n",
            "Max Drawdown [%]                   4.900568\n",
            "Max Drawdown Duration             10.000000\n",
            "Total Trades                       2.000000\n",
            "Total Closed Trades                1.000000\n",
            "Total Open Trades                  1.000000\n",
            "Open Trade PnL                  7842.950122\n",
            "Win Rate [%]                       0.000000\n",
            "Best Trade [%]                    -2.659644\n",
            "Worst Trade [%]                   -2.659644\n",
            "Avg Winning Trade [%]                   NaN\n",
            "Avg Losing Trade [%]              -2.659644\n",
            "Avg Winning Trade Duration              NaN\n",
            "Avg Losing Trade Duration          2.000000\n",
            "Profit Factor                      0.000000\n",
            "Expectancy                     -2656.986783\n",
            "dtype: float64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3311,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "appl_ = merged_data.dropna(subset=['Close_AAPL'])\n",
        "entries = merged_data['Buy_Signal'].astype(bool)\n",
        "exits = merged_data['Sell_Signal'].astype(bool)\n",
        "\n",
        "price = merged_data['Close_AAPL']\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    init_cash=100_000,\n",
        "    fees=0.001\n",
        ")\n",
        "\n",
        "print(portfolio.stats())\n",
        "fig_portfolio_merged = portfolio.plot()\n",
        "st.subheader(\"AAPL Portfolio Performance\")\n",
        "st.plotly_chart(fig_portfolio_merged, use_container_width=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Without Sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3312,
      "metadata": {},
      "outputs": [],
      "source": [
        "# WITHOUT sentiment\n",
        "appl_copy = appl.copy()\n",
        "appl_copy['atr_pct'] = appl_copy['ATR_10'] / appl_copy['Close_AAPL']\n",
        "\n",
        "# Create Buy Signal (assuming VI_Cross_Up is defined elsewhere)\n",
        "appl_copy['Buy_Signal'] = appl_copy['VI+_'] > appl_copy['VI-_']  # Vortex crossover\n",
        "# + add any other buy conditions here...\n",
        "\n",
        "# Create Sell Signal (basic)\n",
        "appl_copy['Sell_Signal'] = appl_copy['VI-_'] > appl_copy['VI+_']\n",
        "\n",
        "# Initialize position state\n",
        "appl_copy['Position'] = 0\n",
        "peak_price = 0\n",
        "\n",
        "for i in range(1, len(appl_copy)):\n",
        "    if appl_copy['Buy_Signal'].iloc[i]:\n",
        "        appl_copy.at[appl_copy.index[i], 'Position'] = 1\n",
        "        peak_price = appl_copy['Close_AAPL'].iloc[i]\n",
        "    elif appl_copy['Position'].iloc[i - 1] == 1:\n",
        "        current_price = appl_copy['Close_AAPL'].iloc[i]\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        if drawdown >= 0.03:\n",
        "            appl_copy.at[appl_copy.index[i], 'Sell_Signal'] = True  # trailing stop\n",
        "            appl_copy.at[appl_copy.index[i], 'Position'] = 0\n",
        "        else:\n",
        "            appl_copy.at[appl_copy.index[i], 'Position'] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3313,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Capital: $101607.34\n",
            "Total Return: $1607.34\n",
            "Total Trades: 66\n",
            "Average Profit per Trade: $24.26\n"
          ]
        }
      ],
      "source": [
        "capital = 100000\n",
        "in_position = False\n",
        "entry_price = 0\n",
        "position_value = 0\n",
        "cash = capital\n",
        "returns = []\n",
        "\n",
        "for i in range(len(appl_copy)):\n",
        "    row = appl_copy.iloc[i]\n",
        "    \n",
        "    # Buy\n",
        "    if row['Buy_Signal'] and not in_position:\n",
        "        position_size = row['position_size']\n",
        "        position_value = cash * position_size\n",
        "        entry_price = row['Close_AAPL']\n",
        "        shares_bought = position_value / entry_price\n",
        "        cash -= position_value\n",
        "        in_position = True\n",
        "        \n",
        "    # Sell\n",
        "    elif row['Sell_Signal'] and in_position:\n",
        "        exit_price = row['Close_AAPL']\n",
        "        proceeds = shares_bought * exit_price\n",
        "        profit = proceeds - position_value\n",
        "        cash += proceeds\n",
        "        returns.append(profit)\n",
        "        in_position = False\n",
        "        position_value = 0\n",
        "        entry_price = 0\n",
        "\n",
        "# Final capital\n",
        "final_value = cash + (shares_bought * row['Close_AAPL'] if in_position else 0)\n",
        "total_return = final_value - capital\n",
        "\n",
        "print(f\"Final Capital: ${final_value:.2f}\")\n",
        "print(f\"Total Return: ${total_return:.2f}\")\n",
        "print(f\"Total Trades: {len(returns)}\")\n",
        "print(f\"Average Profit per Trade: ${np.mean(returns):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3314,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start                         2019-01-02 00:00:00\n",
            "End                           2025-03-04 00:00:00\n",
            "Period                                       1551\n",
            "Start Value                              100000.0\n",
            "End Value                           381936.663857\n",
            "Total Return [%]                       281.936664\n",
            "Benchmark Return [%]                   526.354228\n",
            "Max Gross Exposure [%]                      100.0\n",
            "Total Fees Paid                      35759.568798\n",
            "Max Drawdown [%]                        20.871703\n",
            "Max Drawdown Duration                       351.0\n",
            "Total Trades                                   67\n",
            "Total Closed Trades                            66\n",
            "Total Open Trades                               1\n",
            "Open Trade PnL                        4424.594853\n",
            "Win Rate [%]                            45.454545\n",
            "Best Trade [%]                          41.284317\n",
            "Worst Trade [%]                        -11.056921\n",
            "Avg Winning Trade [%]                    8.072835\n",
            "Avg Losing Trade [%]                    -2.459744\n",
            "Avg Winning Trade Duration              24.766667\n",
            "Avg Losing Trade Duration                6.222222\n",
            "Profit Factor                            2.113946\n",
            "Expectancy                            4204.728318\n",
            "dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sharpe_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'calmar_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'omega_ratio' requires frequency to be set\n",
            "\n",
            "/opt/anaconda3/lib/python3.11/site-packages/vectorbt/generic/stats_builder.py:396: UserWarning:\n",
            "\n",
            "Metric 'sortino_ratio' requires frequency to be set\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3314,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "appl = appl_copy.dropna(subset=['Close_AAPL'])\n",
        "entries = appl_copy['Buy_Signal'].astype(bool)\n",
        "exits = appl_copy['Sell_Signal'].astype(bool)\n",
        "\n",
        "price = appl_copy['Close_AAPL']\n",
        "portfolio = vbt.Portfolio.from_signals(\n",
        "    close=price,\n",
        "    entries=entries,\n",
        "    exits=exits,\n",
        "    init_cash=100_000,\n",
        "    fees=0.001\n",
        ")\n",
        "\n",
        "print(portfolio.stats())\n",
        "fig_portfolio_aapl = portfolio.plot()\n",
        "st.subheader(\"AAPL Portfolio Performance w/o Sentiment\")\n",
        "st.plotly_chart(fig_portfolio_aapl, use_container_width=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the results from applying the trading strategy to the Apple (AAPL) ticker, we can reasonably conclude that the strategy does work on peers like AAPL. The strategy delivered a total return of approximately 282% over the backtest period (2019–2025), compared to a benchmark return of about 526%, which indicates it captured a significant portion of the upward trend while actively managing trades. Although it underperformed the benchmark in absolute terms, this is typical of signal-driven strategies that trade in and out of the market. The profit factor of 2.11, expectancy of 4204, and a win rate of 45.5% suggest the strategy was profitable overall. Additionally, the drawdown was moderate (20.87%), reflecting a reasonable risk exposure relative to the potential reward.\n",
        "\n",
        "The cumulative returns graph further supports this interpretation. The strategy closely follows the broader market trend, generating consistent gains and outperforming during certain periods. The trade PnL distribution shows a good number of winning trades with healthy profitability, and although there were losses, the downside was generally contained. Therefore, this peer comparison confirms that the strategy generalizes reasonably well beyond TSLA, making it a potentially viable approach for other high-liquidity technology stocks like AAPL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3315,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Buy signals: 985\n",
            "Sell signals: 552\n"
          ]
        }
      ],
      "source": [
        "# Calculate ATR percentage\n",
        "appl['atr_pct'] = appl['ATR_10'] / appl['Close_AAPL']\n",
        "appl['Buy_Signal'] = appl['VI+_'] > appl['VI-_']  # Vortex crossover\n",
        "appl['Sell_Signal'] = appl['VI-_'] > appl['VI+_']\n",
        "\n",
        "# Initialize position state\n",
        "appl['Position'] = 0\n",
        "appl['Entry_Type'] = None\n",
        "peak_price = 0\n",
        "\n",
        "for i in range(1, len(appl)):\n",
        "    if appl['Buy_Signal'].iloc[i]:\n",
        "        appl.at[appl.index[i], 'Position'] = 1\n",
        "        peak_price = appl['Close_AAPL'].iloc[i]\n",
        "    elif appl['Position'].iloc[i - 1] == 1:\n",
        "        current_price = appl['Close_AAPL'].iloc[i]\n",
        "        peak_price = max(peak_price, current_price)\n",
        "        drawdown = (peak_price - current_price) / peak_price\n",
        "\n",
        "        if drawdown >= 0.03:\n",
        "            appl.at[appl.index[i], 'Sell_Signal'] = True  # trailing stop\n",
        "            appl.at[appl.index[i], 'Position'] = 0\n",
        "        else:\n",
        "            appl.at[appl.index[i], 'Position'] = 1\n",
        "\n",
        "print(\"Buy signals:\", appl['Buy_Signal'].sum())\n",
        "print(\"Sell signals:\", appl['Sell_Signal'].sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3316,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3316,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create figure\n",
        "fig_aapl_signals = go.Figure()\n",
        "\n",
        "# AAPL price line\n",
        "fig_aapl_signals.add_trace(go.Scatter(\n",
        "    x=appl.index,\n",
        "    y=appl['Close_AAPL'],\n",
        "    mode='lines',\n",
        "    name='AAPL Price'\n",
        "))\n",
        "\n",
        "# Buy signal markers\n",
        "fig_aapl_signals.add_trace(go.Scatter(\n",
        "    x=appl[appl['Buy_Signal']].index,\n",
        "    y=appl[appl['Buy_Signal']]['Close_AAPL'],\n",
        "    mode='markers',\n",
        "    name='Buy Signal',\n",
        "    marker=dict(symbol='triangle-up', size=10, color='green')\n",
        "))\n",
        "\n",
        "# Sell signal markers\n",
        "fig_aapl_signals.add_trace(go.Scatter(\n",
        "    x=appl[appl['Sell_Signal']].index,\n",
        "    y=appl[appl['Sell_Signal']]['Close_AAPL'],\n",
        "    mode='markers',\n",
        "    name='Sell Signal',\n",
        "    marker=dict(symbol='triangle-down', size=10, color='red')\n",
        "))\n",
        "\n",
        "# Layout customization\n",
        "fig_aapl_signals.update_layout(\n",
        "    title='AAPL Buy & Sell Signals',\n",
        "    template='plotly_white'\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"AAPL Buy & Sell Signals\")\n",
        "st.plotly_chart(fig_aapl_signals, use_container_width=True)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VI Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3317,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "tsla = yf.download('TSLA', start='2019-01-01', end='2025-03-05')\n",
        "xly = yf.download('XLY', start='2019-01-01', end='2025-03-05')\n",
        "spy = yf.download('SPY', start='2019-01-01', end='2025-03-05')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3318,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_vortex(df, value, n=14):\n",
        "    high = df[(\"High\", value)]\n",
        "    low = df[(\"Low\", value)]\n",
        "    close = df[(\"Close\", value)]\n",
        "\n",
        "    # Calculate VM+ and VM-\n",
        "    vm_plus = abs(high - low.shift(1))   # |Today's High - Yesterday's Low|\n",
        "    vm_minus = abs(low - high.shift(1))  # |Today's Low - Yesterday's High|\n",
        "\n",
        "    # Calculate True Range (TR)\n",
        "    tr = pd.concat([\n",
        "        high - low,\n",
        "        abs(high - close.shift(1)),\n",
        "        abs(low - close.shift(1))\n",
        "    ], axis=1).max(axis=1)\n",
        "\n",
        "    # Rolling sum for lookback period\n",
        "    sum_vm_plus = vm_plus.rolling(window=n).sum()\n",
        "    sum_vm_minus = vm_minus.rolling(window=n).sum()\n",
        "    sum_tr = tr.rolling(window=n).sum()\n",
        "\n",
        "    # Compute VI+ and VI-\n",
        "    vi_plus = sum_vm_plus / sum_tr\n",
        "    vi_minus = sum_vm_minus / sum_tr\n",
        "\n",
        "    return vi_plus, vi_minus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3319,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsla['VI+'], tsla['VI-'] = calculate_vortex(tsla, 'TSLA')\n",
        "xly['VI+'], xly['VI-'] = calculate_vortex(xly, 'XLY')\n",
        "spy['VI+'], spy['VI-'] = calculate_vortex(spy, 'SPY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3320,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            Close_TSLA     ATR_10   atr_pct  position_size\n",
            "Date                                                      \n",
            "2025-02-19  360.559998  16.703000  0.046325          0.005\n",
            "2025-02-20  354.399994  16.464999  0.046459          0.005\n",
            "2025-02-21  337.799988  17.021997  0.050391          0.005\n",
            "2025-02-24  330.529999  16.770996  0.050740          0.005\n",
            "2025-02-25  302.799988  18.879996  0.062351          0.005\n",
            "2025-02-26  290.799988  18.412994  0.063318          0.005\n",
            "2025-02-27  281.950012  18.257996  0.064756          0.005\n",
            "2025-02-28  292.980011  18.067996  0.061670          0.005\n",
            "2025-03-03  284.649994  19.281998  0.067739          0.005\n",
            "2025-03-04  272.040009  20.654996  0.075926          0.005\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Flatten MultiIndex columns \n",
        "tsla.columns = [\n",
        "    '_'.join(col).strip() if isinstance(col, tuple) else col\n",
        "    for col in tsla.columns\n",
        "]\n",
        "\n",
        "# Calculate True Range\n",
        "tsla[\"prev_close\"] = tsla[\"Close_TSLA\"].shift(1)\n",
        "tsla[\"tr1\"] = tsla[\"High_TSLA\"] - tsla[\"Low_TSLA\"]\n",
        "tsla[\"tr2\"] = abs(tsla[\"High_TSLA\"] - tsla[\"prev_close\"])\n",
        "tsla[\"tr3\"] = abs(tsla[\"Low_TSLA\"] - tsla[\"prev_close\"])\n",
        "\n",
        "tsla[\"true_range\"] = tsla[[\"tr1\", \"tr2\", \"tr3\"]].max(axis=1)\n",
        "\n",
        "# 10-day ATR\n",
        "tsla[\"ATR_10\"] = tsla[\"true_range\"].rolling(window=10).mean()\n",
        "\n",
        "# ---- STEP 4: Calculate ATR as a percentage of closing price ----\n",
        "tsla[\"atr_pct\"] = tsla[\"ATR_10\"] / tsla[\"Close_TSLA\"]\n",
        "\n",
        "# allocating the capital\n",
        "\n",
        "def position_size(row):\n",
        "    if row[\"atr_pct\"] < 0.03:  # < 3% volatility → low risk\n",
        "        return 0.01  # allocate 1% of capital\n",
        "    else:  # ≥ 3% volatility → high risk\n",
        "        return 0.005  # allocate 0.5% of capital\n",
        "\n",
        "tsla[\"position_size\"] = tsla.apply(position_size, axis=1)\n",
        "\n",
        "# ---- STEP 6: Optional - Capital allocation per trade ----\n",
        "#capital = 100000 # Example: $100K total portfolio\n",
        "#tsla[\"allocation_dollars\"] = tsla[\"position_size\"] * capital\n",
        "\n",
        "# ---- Preview ----\n",
        "print(tsla[[\"Close_TSLA\", \"ATR_10\", \"atr_pct\", \"position_size\"]].tail(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3321,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/lib/python3.11/site-packages/_plotly_utils/basevalidators.py:106: FutureWarning:\n",
            "\n",
            "The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3321,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the line chart to visualize the ATR%\n",
        "fig_atr_tsla = px.line(\n",
        "    tsla,\n",
        "    x=tsla.index,\n",
        "    y=\"atr_pct\",\n",
        "    title=\"ATR% Over Time for TSLA\"\n",
        ")\n",
        "\n",
        "# Add a horizontal line for the low volatility threshold at 3%\n",
        "fig_atr_tsla.add_hline(\n",
        "    y=0.03,\n",
        "    line_dash=\"dot\",\n",
        "    line_color=\"green\",\n",
        "    annotation_text=\"Low Volatility Cutoff\"\n",
        ")\n",
        "\n",
        "# Display title and chart in Streamlit with a unique key\n",
        "st.subheader(\"ATR% Over Time for TSLA\")\n",
        "st.plotly_chart(fig_atr_tsla, use_container_width=True, key=\"atr_tsla_chart\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3322,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3322,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the figure for TSLA full period\n",
        "fig_tsla_full = go.Figure()\n",
        "\n",
        "# Add VI+ trace\n",
        "fig_tsla_full.add_trace(go.Scatter(\n",
        "    x=tsla.index,\n",
        "    y=tsla[\"VI+_\"],\n",
        "    mode='lines',\n",
        "    name='VI+_',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Add VI- trace\n",
        "fig_tsla_full.add_trace(go.Scatter(\n",
        "    x=tsla.index,\n",
        "    y=tsla[\"VI-_\"],\n",
        "    mode='lines',\n",
        "    name='VI-_',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Customize layout\n",
        "fig_tsla_full.update_layout(\n",
        "    title=\"Vortex Indicator (VI+ and VI−) for TSLA\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Value\",\n",
        "    legend=dict(x=0, y=1.1, orientation=\"h\"),\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"Vortex Indicator for TSLA - Full Period\")\n",
        "st.plotly_chart(fig_tsla_full, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3323,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3323,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter TSLA data for 2025\n",
        "tsla_2025 = tsla.loc[\"2025\"]\n",
        "\n",
        "# Create the figure\n",
        "fig_tsla_2025 = go.Figure()\n",
        "\n",
        "# Add VI+ trace\n",
        "fig_tsla_2025.add_trace(go.Scatter(\n",
        "    x=tsla_2025.index,\n",
        "    y=tsla_2025[\"VI+_\"],\n",
        "    mode='lines',\n",
        "    name='VI+_',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Add VI- trace\n",
        "fig_tsla_2025.add_trace(go.Scatter(\n",
        "    x=tsla_2025.index,\n",
        "    y=tsla_2025[\"VI-_\"],\n",
        "    mode='lines',\n",
        "    name='VI-_',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Update layout\n",
        "fig_tsla_2025.update_layout(\n",
        "    title=\"Vortex Indicator (VI+ and VI−) for TSLA – 2025\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Value\",\n",
        "    legend=dict(x=0, y=1.1, orientation=\"h\"),\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"Vortex Indicator for TSLA - 2025\")\n",
        "st.plotly_chart(fig_tsla_2025, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3324,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3324,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the figure with a unique name\n",
        "fig_spy_full = go.Figure()\n",
        "\n",
        "# Add VI+ trace\n",
        "fig_spy_full.add_trace(go.Scatter(\n",
        "    x=spy.index,\n",
        "    y=spy[\"VI+\"],\n",
        "    mode='lines',\n",
        "    name='VI+',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Add VI- trace\n",
        "fig_spy_full.add_trace(go.Scatter(\n",
        "    x=spy.index,\n",
        "    y=spy[\"VI-\"],\n",
        "    mode='lines',\n",
        "    name='VI-',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Customize layout\n",
        "fig_spy_full.update_layout(\n",
        "    title=\"Vortex Indicator (VI+ and VI−) for SPY\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Value\",\n",
        "    legend=dict(x=0, y=1.1, orientation=\"h\"),\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"Vortex Indicator for SPY - Full Period\")\n",
        "st.plotly_chart(fig_spy_full, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3325,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3325,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter SPY data for 2025\n",
        "spy_2025 = spy.loc[\"2025\"]\n",
        "\n",
        "# Create the figure\n",
        "fig_spy_2025 = go.Figure()\n",
        "\n",
        "# Add VI+ trace\n",
        "fig_spy_2025.add_trace(go.Scatter(\n",
        "    x=spy_2025.index,\n",
        "    y=spy_2025[\"VI+\"],\n",
        "    mode='lines',\n",
        "    name='VI+',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Add VI- trace\n",
        "fig_spy_2025.add_trace(go.Scatter(\n",
        "    x=spy_2025.index,\n",
        "    y=spy_2025[\"VI-\"],\n",
        "    mode='lines',\n",
        "    name='VI-',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Update layout\n",
        "fig_spy_2025.update_layout(\n",
        "    title=\"Vortex Indicator (VI+ and VI−) for SPY – 2025\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Value\",\n",
        "    legend=dict(x=0, y=1.1, orientation=\"h\"),\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"Vortex Indicator for SPY - 2025\")\n",
        "st.plotly_chart(fig_spy_2025, use_container_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3326,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the figure with a descriptive name\n",
        "fig_xly_full = go.Figure()\n",
        "\n",
        "# Add VI+ trace\n",
        "fig_xly_full.add_trace(go.Scatter(\n",
        "    x=xly.index,\n",
        "    y=xly[\"VI+\"],\n",
        "    mode='lines',\n",
        "    name='VI+',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Add VI- trace\n",
        "fig_xly_full.add_trace(go.Scatter(\n",
        "    x=xly.index,\n",
        "    y=xly[\"VI-\"],\n",
        "    mode='lines',\n",
        "    name='VI-',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Layout customization\n",
        "fig_xly_full.update_layout(\n",
        "    title=\"Vortex Indicator (VI+ and VI−) for XLY\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Value\",\n",
        "    legend=dict(x=0, y=1.1, orientation=\"h\"),\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "# Render using Streamlit\n",
        "st.subheader(\"Vortex Indicator for XLY - Full Period\")\n",
        "st.plotly_chart(fig_xly_full, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3327,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3327,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter the XLY data for 2025\n",
        "xly_2025 = xly.loc[\"2025\"]\n",
        "\n",
        "# Create the figure with a unique name\n",
        "fig_xly_2025 = go.Figure()\n",
        "\n",
        "# Add VI+ line\n",
        "fig_xly_2025.add_trace(go.Scatter(\n",
        "    x=xly_2025.index,\n",
        "    y=xly_2025[\"VI+\"],\n",
        "    mode='lines',\n",
        "    name='VI+',\n",
        "    line=dict(color='blue')\n",
        "))\n",
        "\n",
        "# Add VI- line\n",
        "fig_xly_2025.add_trace(go.Scatter(\n",
        "    x=xly_2025.index,\n",
        "    y=xly_2025[\"VI-\"],\n",
        "    mode='lines',\n",
        "    name='VI-',\n",
        "    line=dict(color='orange')\n",
        "))\n",
        "\n",
        "# Layout styling\n",
        "fig_xly_2025.update_layout(\n",
        "    title=\"Vortex Indicator (VI+ and VI−) for XLY – 2025\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Value\",\n",
        "    legend=dict(x=0, y=1.1, orientation=\"h\"),\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "# Display in Streamlit\n",
        "st.subheader(\"Vortex Indicator for XLY – 2025\")\n",
        "st.plotly_chart(fig_xly_2025, use_container_width=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3328,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3328,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig_2025 = make_subplots(\n",
        "    rows=3, cols=1,\n",
        "    subplot_titles=(\"SPY - 2025\", \"XLY - 2025\", \"TSLA - 2025\")\n",
        ")\n",
        "\n",
        "fig_2025.add_trace(go.Scatter(\n",
        "    x=spy_2025.index,\n",
        "    y=spy_2025[\"VI+\"],\n",
        "    name=\"VI+ (SPY)\",\n",
        "    line=dict(color='blue'),\n",
        "    showlegend=False\n",
        "), row=1, col=1)\n",
        "\n",
        "fig_2025.add_trace(go.Scatter(\n",
        "    x=spy_2025.index,\n",
        "    y=spy_2025[\"VI-\"],\n",
        "    name=\"VI- (SPY)\",\n",
        "    line=dict(color='orange'),\n",
        "    showlegend=False\n",
        "), row=1, col=1)\n",
        "\n",
        "fig_2025.add_trace(go.Scatter(\n",
        "    x=xly_2025.index,\n",
        "    y=xly_2025[\"VI+\"],\n",
        "    name=\"VI+ (XLY)\",\n",
        "    line=dict(color='blue'),\n",
        "    showlegend=False\n",
        "), row=2, col=1)\n",
        "\n",
        "fig_2025.add_trace(go.Scatter(\n",
        "    x=xly_2025.index,\n",
        "    y=xly_2025[\"VI-\"],\n",
        "    name=\"VI- (XLY)\",\n",
        "    line=dict(color='orange'),\n",
        "    showlegend=False\n",
        "), row=2, col=1)\n",
        "\n",
        "fig_2025.add_trace(go.Scatter(\n",
        "    x=tsla_2025.index,\n",
        "    y=tsla_2025[\"VI+_\"],\n",
        "    name=\"VI+ (TSLA)\",\n",
        "    line=dict(color='blue'),\n",
        "    showlegend=False\n",
        "), row=3, col=1)\n",
        "\n",
        "fig_2025.add_trace(go.Scatter(\n",
        "    x=tsla_2025.index,\n",
        "    y=tsla_2025[\"VI-_\"],\n",
        "    name=\"VI- (TSLA)\",\n",
        "    line=dict(color='orange'),\n",
        "    showlegend=False\n",
        "), row=3, col=1)\n",
        "\n",
        "fig_2025.update_layout(\n",
        "    height=500, width=1200,\n",
        "    title_text=\"Vortex Indicator (VI+ and VI−) - 2025 Comparison\",\n",
        "    template=\"plotly_white\"\n",
        ")\n",
        "\n",
        "st.plotly_chart(fig_2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3330,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 3330,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fig_full = make_subplots(\n",
        "    rows=3, cols=1,\n",
        "    subplot_titles=(\"SPY Year To Year\", \"XLY Year To Year\", \"TSLA Year To Year\")\n",
        ")\n",
        "\n",
        "fig_full.add_trace(go.Scatter(\n",
        "    x=spy.index,\n",
        "    y=spy[\"VI+\"],\n",
        "    name=\"VI+ (SPY)\",\n",
        "    line=dict(color='blue'),\n",
        "    showlegend=False\n",
        "), row=1, col=1)\n",
        "\n",
        "fig_full.add_trace(go.Scatter(\n",
        "    x=spy.index,\n",
        "    y=spy[\"VI-\"],\n",
        "    name=\"VI- (SPY)\",\n",
        "    line=dict(color='orange'),\n",
        "    showlegend=False\n",
        "), row=1, col=1)\n",
        "\n",
        "fig_full.add_trace(go.Scatter(\n",
        "    x=xly.index,\n",
        "    y=xly[\"VI+\"],\n",
        "    name=\"VI+ (XLY)\",\n",
        "    line=dict(color='blue'),\n",
        "    showlegend=False\n",
        "), row=2, col=1)\n",
        "\n",
        "fig_full.add_trace(go.Scatter(\n",
        "    x=xly.index,\n",
        "    y=xly[\"VI-\"],\n",
        "    name=\"VI- (XLY)\",\n",
        "    line=dict(color='orange'),\n",
        "    showlegend=False\n",
        "), row=2, col=1)\n",
        "\n",
        "fig_full.add_trace(go.Scatter(\n",
        "    x=tsla.index,\n",
        "    y=tsla[\"VI+_\"],\n",
        "    name=\"VI+ (TSLA)\",\n",
        "    line=dict(color='blue'),\n",
        "    showlegend=False\n",
        "), row=3, col=1)\n",
        "\n",
        "fig_full.add_trace(go.Scatter(\n",
        "    x=tsla.index,\n",
        "    y=tsla[\"VI-_\"],\n",
        "    name=\"VI- (TSLA)\",\n",
        "    line=dict(color='orange'),\n",
        "    showlegend=False\n",
        "), row=3, col=1)\n",
        "\n",
        "fig_full.update_layout(\n",
        "    height=900, width=1200,\n",
        "    title_text=\"Vortex Indicator (VI+ and VI−) – Full Period Comparison\",\n",
        "    template=\"plotly_white\",\n",
        "    shapes=[\n",
        "        # COVID Crash\n",
        "        dict(type=\"rect\", xref=\"x\", yref=\"paper\",\n",
        "             x0=\"2020-02-15\", x1=\"2020-08-15\", y0=0, y1=1,\n",
        "             fillcolor=\"LightBlue\", opacity=0.3, layer=\"below\", line_width=0),\n",
        "        \n",
        "        # Inflation Regime\n",
        "        dict(type=\"rect\", xref=\"x\", yref=\"paper\",\n",
        "             x0=\"2021-11-01\", x1=\"2023-07-01\", y0=0, y1=1,\n",
        "             fillcolor=\"LightSalmon\", opacity=0.3, layer=\"below\", line_width=0),\n",
        "\n",
        "        # AI Boom\n",
        "        dict(type=\"rect\", xref=\"x\", yref=\"paper\",\n",
        "             x0=\"2023-01-01\", x1=\"2025-12-31\", y0=0, y1=1,\n",
        "             fillcolor=\"LightGreen\", opacity=0.2, layer=\"below\", line_width=0)\n",
        "    ],\n",
        "    annotations=[\n",
        "        dict(x=\"2020-04-15\", y=1.45, xref=\"x\", yref=\"paper\",\n",
        "             text=\"COVID Shock\", showarrow=False, font=dict(size=10)),\n",
        "        dict(x=\"2022-06-01\", y=1.45, xref=\"x\", yref=\"paper\",\n",
        "             text=\"Inflation Spike\", showarrow=False, font=dict(size=10)),\n",
        "        dict(x=\"2024-01-01\", y=1.45, xref=\"x\", yref=\"paper\",\n",
        "             text=\"AI Rally / Soft Landing\", showarrow=False, font=dict(size=10))\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "st.plotly_chart(fig_full)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
